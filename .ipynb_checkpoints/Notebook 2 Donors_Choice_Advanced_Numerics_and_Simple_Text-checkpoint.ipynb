{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Donor's Choose Capstone 2 Project (Notebook 2)\n",
    "\n",
    "This notebook contains the the next step in the Donor's choice project.  It will add cost analysis by state, and simple text analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2:  Advanced Cost Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hypothesis*    Given the differences visible in the visual data analysis across states for subject approvals, it is reasonable to check if there is alsoa geographic dependence on project cost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All functions and imports are at bottom of notebook and must be run prior to proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read working file\n",
    "work_df=pd.read_csv(__data_dir__+'1_numerics_no_dummies.csv')\n",
    "work2_df=work_df.copy() #save work_df for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before state costs22 columns in work_df and  182080 lines\n",
      "df looking for : avg_st_proj_cost Index([u'proj_id', u'teacher_id', u'teacher_prefix', u'school_state',\n",
      "       u'project_submitted_datetime', u'project_grade_category',\n",
      "       u'project_subject_categories', u'project_subject_subcategories',\n",
      "       u'project_title', u'project_essay_1', u'project_essay_2',\n",
      "       u'project_essay_3', u'project_essay_4', u'project_resource_summary',\n",
      "       u'teacher_number_of_previously_posted_projects', u'project_is_approved',\n",
      "       u'month', u'1st_cat', u'proj_cost', u'cost_bin', u'currents',\n",
      "       u'exp_bin', u'avg_st_proj_cost'],\n",
      "      dtype='object')\n",
      "After state costs 42 columns in work_df and  182080 lines\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proj_id</th>\n",
       "      <th>teacher_id</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>school_state</th>\n",
       "      <th>project_submitted_datetime</th>\n",
       "      <th>project_grade_category</th>\n",
       "      <th>project_subject_categories</th>\n",
       "      <th>project_subject_subcategories</th>\n",
       "      <th>project_title</th>\n",
       "      <th>project_essay_1</th>\n",
       "      <th>project_essay_2</th>\n",
       "      <th>project_essay_3</th>\n",
       "      <th>project_essay_4</th>\n",
       "      <th>project_resource_summary</th>\n",
       "      <th>teacher_number_of_previously_posted_projects</th>\n",
       "      <th>project_is_approved</th>\n",
       "      <th>month</th>\n",
       "      <th>1st_cat</th>\n",
       "      <th>proj_cost</th>\n",
       "      <th>cost_bin</th>\n",
       "      <th>currents</th>\n",
       "      <th>exp_bin</th>\n",
       "      <th>avg_st_proj_cost</th>\n",
       "      <th>cost_delta</th>\n",
       "      <th>quantity</th>\n",
       "      <th>avg_st_items</th>\n",
       "      <th>qty_delta</th>\n",
       "      <th>max_item_price</th>\n",
       "      <th>st_mx_item</th>\n",
       "      <th>max_price_delta</th>\n",
       "      <th>min_item_price</th>\n",
       "      <th>st_min_item</th>\n",
       "      <th>min_price_delta</th>\n",
       "      <th>avg_item_price</th>\n",
       "      <th>st_avg_item</th>\n",
       "      <th>avg_price_delta</th>\n",
       "      <th>maxdmin</th>\n",
       "      <th>maxdavg</th>\n",
       "      <th>maxdstmax</th>\n",
       "      <th>avgdstavg</th>\n",
       "      <th>mindavg</th>\n",
       "      <th>mindstmin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p036502</td>\n",
       "      <td>484aaf11257089a66cfedc9461c6bd0a</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>NV</td>\n",
       "      <td>2016-11-18 14:45:00</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Super Sight Word Centers</td>\n",
       "      <td>Most of my kindergarten students come from low...</td>\n",
       "      <td>I currently have a differentiated sight word c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need 6 Ipod Nano's to create and d...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>899.94</td>\n",
       "      <td>750</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>554.362</td>\n",
       "      <td>-345.58</td>\n",
       "      <td>6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>149.99</td>\n",
       "      <td>192.99</td>\n",
       "      <td>9.2</td>\n",
       "      <td>149.99</td>\n",
       "      <td>108.219552</td>\n",
       "      <td>9.2</td>\n",
       "      <td>149.99</td>\n",
       "      <td>140.03</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p039565</td>\n",
       "      <td>df72a3ba8089423fa8a94be88060f6ed</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>GA</td>\n",
       "      <td>2017-04-26 15:57:00</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Music &amp; The Arts, Health &amp; Sports</td>\n",
       "      <td>Performing Arts, Team Sports</td>\n",
       "      <td>Keep Calm and Dance On</td>\n",
       "      <td>Our elementary school is a culturally rich sch...</td>\n",
       "      <td>We strive to provide our diverse population of...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need matching shirts to wear for d...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>400.00</td>\n",
       "      <td>250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>571.246</td>\n",
       "      <td>171.25</td>\n",
       "      <td>20</td>\n",
       "      <td>15.1</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198.23</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>20.00</td>\n",
       "      <td>101.294929</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>20.00</td>\n",
       "      <td>136.69</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p233823</td>\n",
       "      <td>a9b876a9252e08a55e3d894150f75ba3</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>UT</td>\n",
       "      <td>2017-01-01 22:57:00</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>Math &amp; Science, Literacy &amp; Language</td>\n",
       "      <td>Applied Sciences, Literature &amp; Writing</td>\n",
       "      <td>Lets 3Doodle to Learn</td>\n",
       "      <td>Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...</td>\n",
       "      <td>We are looking to add some 3Doodler to our cla...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My students need the 3doodler. We are an SEM s...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>469.99</td>\n",
       "      <td>250</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>619.784</td>\n",
       "      <td>149.79</td>\n",
       "      <td>1</td>\n",
       "      <td>19.3</td>\n",
       "      <td>18.3</td>\n",
       "      <td>469.99</td>\n",
       "      <td>189.04</td>\n",
       "      <td>18.3</td>\n",
       "      <td>469.99</td>\n",
       "      <td>94.772210</td>\n",
       "      <td>18.3</td>\n",
       "      <td>469.99</td>\n",
       "      <td>127.65</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.49</td>\n",
       "      <td>3.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   proj_id                        teacher_id teacher_prefix school_state  \\\n",
       "0  p036502  484aaf11257089a66cfedc9461c6bd0a            Ms.           NV   \n",
       "1  p039565  df72a3ba8089423fa8a94be88060f6ed           Mrs.           GA   \n",
       "2  p233823  a9b876a9252e08a55e3d894150f75ba3            Ms.           UT   \n",
       "\n",
       "  project_submitted_datetime project_grade_category  \\\n",
       "0        2016-11-18 14:45:00          Grades PreK-2   \n",
       "1        2017-04-26 15:57:00             Grades 3-5   \n",
       "2        2017-01-01 22:57:00             Grades 3-5   \n",
       "\n",
       "            project_subject_categories  \\\n",
       "0                  Literacy & Language   \n",
       "1    Music & The Arts, Health & Sports   \n",
       "2  Math & Science, Literacy & Language   \n",
       "\n",
       "            project_subject_subcategories             project_title  \\\n",
       "0                                Literacy  Super Sight Word Centers   \n",
       "1            Performing Arts, Team Sports    Keep Calm and Dance On   \n",
       "2  Applied Sciences, Literature & Writing     Lets 3Doodle to Learn   \n",
       "\n",
       "                                     project_essay_1  \\\n",
       "0  Most of my kindergarten students come from low...   \n",
       "1  Our elementary school is a culturally rich sch...   \n",
       "2  Hello;\\r\\nMy name is Mrs. Brotherton. I teach ...   \n",
       "\n",
       "                                     project_essay_2 project_essay_3  \\\n",
       "0  I currently have a differentiated sight word c...             NaN   \n",
       "1  We strive to provide our diverse population of...             NaN   \n",
       "2  We are looking to add some 3Doodler to our cla...             NaN   \n",
       "\n",
       "  project_essay_4                           project_resource_summary  \\\n",
       "0             NaN  My students need 6 Ipod Nano's to create and d...   \n",
       "1             NaN  My students need matching shirts to wear for d...   \n",
       "2             NaN  My students need the 3doodler. We are an SEM s...   \n",
       "\n",
       "   teacher_number_of_previously_posted_projects  project_is_approved  month  \\\n",
       "0                                            26                    1     11   \n",
       "1                                             1                    0      4   \n",
       "2                                             5                    1      1   \n",
       "\n",
       "               1st_cat  proj_cost  cost_bin  currents  exp_bin  \\\n",
       "0  Literacy & Language     899.94       750        10       25   \n",
       "1     Music & The Arts     400.00       250         1        0   \n",
       "2       Math & Science     469.99       250         4        5   \n",
       "\n",
       "   avg_st_proj_cost  cost_delta  quantity  avg_st_items  qty_delta  \\\n",
       "0           554.362     -345.58         6          15.2        9.2   \n",
       "1           571.246      171.25        20          15.1       -4.9   \n",
       "2           619.784      149.79         1          19.3       18.3   \n",
       "\n",
       "   max_item_price  st_mx_item  max_price_delta  min_item_price  st_min_item  \\\n",
       "0          149.99      192.99              9.2          149.99   108.219552   \n",
       "1           20.00      198.23             -4.9           20.00   101.294929   \n",
       "2          469.99      189.04             18.3          469.99    94.772210   \n",
       "\n",
       "   min_price_delta  avg_item_price  st_avg_item  avg_price_delta  maxdmin  \\\n",
       "0              9.2          149.99       140.03              9.2      1.0   \n",
       "1             -4.9           20.00       136.69             -4.9      1.0   \n",
       "2             18.3          469.99       127.65             18.3      1.0   \n",
       "\n",
       "   maxdavg  maxdstmax  avgdstavg  mindavg  mindstmin  \n",
       "0      1.0       0.78       1.07      1.0       1.39  \n",
       "1      1.0       0.10       0.15      1.0       0.20  \n",
       "2      1.0       2.49       3.68      1.0       4.96  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work2_df=work_df.copy()\n",
    "print \"Before state costs{} columns in work_df and  {} lines\".format(len(work2_df.columns),work2_df.proj_id.count())\n",
    "work2_df=get_proj_costs_state(work2_df)\n",
    "print \"After state costs {} columns in work_df and  {} lines\".format(len(work2_df.columns),work2_df.proj_id.count())\n",
    "work2_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check progress and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before string check, df had:106 columns, after check: 95 columns\n",
      "Total test cases: 60087\n",
      "clf 0.846805465408\n",
      "Confusion Matrix for:  Gradient Boost\n",
      "\tActuals\n",
      "Pred.\t0\t1\t\tCorrect= 50882 \t\t0.846805465408\n",
      "0 \t6 \t5 \t\tFalse Negatives= 9200 \t8.32126749546e-05\n",
      "1 \t9200 \t50876 \t\tFalse Positives= 5 \t0.153111321917\n",
      "\n",
      "\n",
      "GB roc_aucscore_= 0.69778\n",
      "ranfor 0.823339491071\n",
      "Confusion Matrix for:  Random Forest\n",
      "\tActuals\n",
      "Pred.\t0\t1\t\tCorrect= 49472 \t\t0.823339491071\n",
      "0 \t895 \t2304 \t\tFalse Negatives= 8311 \t0.0383444006191\n",
      "1 \t8311 \t48577 \t\tFalse Positives= 2304 \t0.13831610831\n",
      "\n",
      "\n",
      "RF roc_aucscore_= 0.61903\n"
     ]
    }
   ],
   "source": [
    "def check_con_mat_progress(df):\n",
    "    '''call:  check_con_mat_progress(df)  where df has features, but has not had dummies applied.\n",
    "    generate confidence matrices'''\n",
    "    tmp=df.copy()\n",
    "    tmp_w_dummies= pd.get_dummies(tmp, prefix='D_', columns=['1st_cat','project_grade_category',\n",
    "                                                             'teacher_prefix','school_state'])\n",
    "    \n",
    "    # Drop all string features\n",
    "    s1=len(tmp_w_dummies.columns)\n",
    "    for c in tmp_w_dummies.columns:\n",
    "        if isinstance(tmp_w_dummies[c].any(),str):\n",
    "            tmp_w_dummies.drop(c,inplace=True,axis=1)\n",
    "    print \"Before string check, df had:{} columns, after check: {} columns\".format(s1,len(tmp_w_dummies.columns))\n",
    "\n",
    "    target=tmp_w_dummies['project_is_approved'].values\n",
    "    feats=tmp_w_dummies.drop('project_is_approved',axis=1)\n",
    "\n",
    "    # Check baseline results:\n",
    "    # clf=GradientBoost Classifier, con_b= associated confusion matrix\n",
    "    # ranfor=Random Forrest Classifier, con_f= associated confusion matrix\n",
    "\n",
    "    clf,con_b,rocky_gb,ranfor,con_f,rocky_rf=get_default_model_results(feats, target)\n",
    "    #analyze_var_impact(con_f,con_f)\n",
    "    \n",
    "    return con_b,rocky_gb,con_f,rocky_rf\n",
    "\n",
    "GB_con,rocky_gb,RF_con,rocky_rf=check_con_mat_progress(work2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "      Feat_set        TP      TN        FP        FN       roc\n",
      "0          raw  0.846789  0.0000  0.153211  0.000000  0.500000\n",
      "1     numerics  0.846772  0.0000  0.153211  0.000017  0.592839\n",
      "2  state_costs  0.846706  0.0001  0.153111  0.000083  0.697778 \n",
      "\n",
      "\n",
      "      Feat_set        TP        TN        FP        FN       roc\n",
      "0          raw  0.846789  0.000000  0.153211  0.000000  0.500000\n",
      "1     numerics  0.796445  0.011933  0.141278  0.050344  0.535634\n",
      "2  state_costs  0.808444  0.014895  0.138316  0.038344  0.619028\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEJCAYAAACdePCvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "rf_results=pd.read_csv(__data_dir__+'rf_basic_results.csv',index_col=0)\n",
    "gb_results=pd.read_csv(__data_dir__+'gb_basic_results.csv',index_col=0)\n",
    "\n",
    "def add_con_mat_results(df,conditions,con_mat,roc_scr):\n",
    "    indy=len(df.index)\n",
    "    df.loc[indy,'Feat_set']=conditions\n",
    "    df.loc[indy,'TP']=con_mat[1,1]\n",
    "    df.loc[indy,'TN']=con_mat[0,0]\n",
    "    df.loc[indy,'FP']=con_mat[0,1]\n",
    "    df.loc[indy,'FN']=con_mat[1,0]\n",
    "    df.loc[indy,'roc']=roc_scr\n",
    "    return df\n",
    "\n",
    "\n",
    "conditions='state_costs'\n",
    "gb_results=add_con_mat_results(gb_results,conditions,GB_con,rocky_gb)\n",
    "rf_results=add_con_mat_results(rf_results,conditions,RF_con,rocky_rf)\n",
    "\n",
    "\n",
    "total=GB_con.sum()\n",
    "gb_tmp=gb_results.copy()\n",
    "rf_tmp=rf_results.copy()\n",
    "col_tf=['TP','TN','FP','FN']\n",
    "for c in col_tf:\n",
    "    gb_tmp[c]=gb_tmp[c]/total\n",
    "    rf_tmp[c]=rf_tmp[c]/total\n",
    "    \n",
    "print '#################\\n',gb_tmp.head(10),'\\n\\n'\n",
    "print rf_tmp.head(10)\n",
    "\n",
    "def plot_model_results(df,name,color1,color2,color3,color4):\n",
    "    correct=df['TP']+df['TN']\n",
    "    plt.plot(df.Feat_set,correct,color=color1,label=name+' correct')\n",
    "    plt.plot(df.Feat_set,df['FP'],color=color2,label=name+' FP')\n",
    "    plt.plot(df.Feat_set,df['FN'],'.-',color=color3,label=name+' FN')\n",
    "    plt.plot(df.Feat_set,df['roc'],'--',color=color4,label=name+' roc')\n",
    "    return\n",
    "\n",
    "\n",
    "plot_model_results(gb_tmp,'GB','lightgreen','darkgreen','palegreen','seagreen')\n",
    "plot_model_results(rf_tmp,'RF','lightcoral','darkred','firebrick','indianred')\n",
    "plt.title('Model performance through '+gb_tmp.Feat_set[len(gb_tmp.index)-1])\n",
    "plt.legend(loc='best',ncol=2)\n",
    "plt.show()\n",
    "\n",
    "rf_results.to_csv(__data_dir__+'rf_basic_results.csv')\n",
    "gb_results.to_csv(__data_dir__+'gb_basic_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save the working_file with and without dummie for later analysis.  \n",
    "all_num_state=pd.get_dummies(work2_df, prefix='D_', columns=['1st_cat','project_grade_category',\n",
    "                                                             'teacher_prefix','school_state'])\n",
    "\n",
    "all_num_state.to_csv(__data_dir__+'basic_num_state_and_dummies.csv',index=False)\n",
    "work2_df.to_csv(__data_dir__+'1_num_state_no_dummies.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Simple Text Preparation - no tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time (local): 11:23:41\n",
      "train length 182080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bill\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2821: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if self.run_code(code, result):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test length 78035\n",
      "total_length 260115\n",
      "Starting: train\n",
      "train file loaded.\n",
      "Essay similarity done. 43 total col\n",
      "project_title \tLabel,length,cap_count, and unique words done.\n",
      "project_title label, len, etc. complete.\n",
      "Elapsed time= 0 min 43 secs\n",
      "Elapsed time= 3 min 43 secs\n",
      "project_title Pol/Subj done. 3 min 43 secs\n",
      "project_title Screened/no stops\n",
      "Elapsed time= 3 min 51 secs\n",
      "Summary for model:\n",
      "strings 17 ints 14 floats 27 others 0 total columns 58 total rows 182080\n",
      "Max features possible: 41\n",
      "project_resource_summary \tLabel,length,cap_count, and unique words done.\n",
      "project_resource_summary label, len, etc. complete.\n",
      "Elapsed time= 4 min 37 secs\n",
      "Elapsed time= 8 min 23 secs\n",
      "project_resource_summary Pol/Subj done. 8 min 23 secs\n",
      "project_resource_summary Screened/no stops\n",
      "Elapsed time= 8 min 35 secs\n",
      "Summary for model:\n",
      "strings 19 ints 21 floats 33 others 0 total columns 73 total rows 182080\n",
      "Max features possible: 54\n",
      "project_essay_1 \tLabel,length,cap_count, and unique words done.\n",
      "project_essay_1 label, len, etc. complete.\n",
      "Elapsed time= 9 min 43 secs\n",
      "Elapsed time= 18 min 31 secs\n",
      "project_essay_1 Pol/Subj done. 18 min 31 secs\n",
      "project_essay_1 Screened/no stops\n",
      "Elapsed time= 19 min 13 secs\n",
      "Summary for model:\n",
      "strings 21 ints 28 floats 39 others 0 total columns 88 total rows 182080\n",
      "Max features possible: 67\n",
      "project_essay_2 \tLabel,length,cap_count, and unique words done.\n",
      "project_essay_2 label, len, etc. complete.\n",
      "Elapsed time= 20 min 36 secs\n",
      "Elapsed time= 30 min 32 secs\n",
      "project_essay_2 Pol/Subj done. 30 min 32 secs\n",
      "project_essay_2 Screened/no stops\n",
      "Elapsed time= 31 min 25 secs\n",
      "Summary for model:\n",
      "strings 23 ints 35 floats 45 others 0 total columns 103 total rows 182080\n",
      "Max features possible: 80\n",
      "project_essay_3 \tLabel,length,cap_count, and unique words done.\n",
      "project_essay_3 label, len, etc. complete.\n",
      "Elapsed time= 32 min 26 secs\n",
      "Elapsed time= 35 min 8 secs\n",
      "project_essay_3 Pol/Subj done. 35 min 8 secs\n",
      "project_essay_3 Screened/no stops\n",
      "Elapsed time= 35 min 17 secs\n",
      "Summary for model:\n",
      "strings 25 ints 42 floats 51 others 0 total columns 118 total rows 182080\n",
      "Max features possible: 93\n",
      "project_essay_4 \tLabel,length,cap_count, and unique words done.\n",
      "project_essay_4 label, len, etc. complete.\n",
      "Elapsed time= 36 min 13 secs\n",
      "Elapsed time= 38 min 52 secs\n",
      "project_essay_4 Pol/Subj done. 38 min 52 secs\n",
      "project_essay_4 Screened/no stops\n",
      "Elapsed time= 39 min 1 secs\n",
      "Summary for model:\n",
      "strings 27 ints 49 floats 57 others 0 total columns 133 total rows 182080\n",
      "Max features possible: 106\n",
      "project_subject_categories \tLabel,length,cap_count, and unique words done.\n",
      "project_subject_categories label, len, etc. complete.\n",
      "Elapsed time= 39 min 58 secs\n",
      "Elapsed time= 42 min 48 secs\n",
      "project_subject_categories Pol/Subj done. 42 min 48 secs\n",
      "project_subject_categories Screened/no stops\n",
      "Elapsed time= 42 min 58 secs\n",
      "Summary for model:\n",
      "strings 29 ints 56 floats 63 others 0 total columns 148 total rows 182080\n",
      "Max features possible: 119\n",
      "project_subject_subcategories \tLabel,length,cap_count, and unique words done.\n",
      "project_subject_subcategories label, len, etc. complete.\n",
      "Elapsed time= 43 min 58 secs\n",
      "Elapsed time= 46 min 48 secs\n",
      "project_subject_subcategories Pol/Subj done. 46 min 48 secs\n",
      "project_subject_subcategories Screened/no stops\n",
      "Elapsed time= 46 min 58 secs\n",
      "Summary for model:\n",
      "strings 31 ints 63 floats 69 others 0 total columns 163 total rows 182080\n",
      "Max features possible: 132\n"
     ]
    }
   ],
   "source": [
    "#Text column preparation\n",
    "# Note:  This is simple text only and does not include tfidf\n",
    "\n",
    "local_timer=timex.get_start_time()\n",
    "\n",
    "#For first pass, work only on training data.\n",
    "#data_set=['train','test']\n",
    "data_set=['train']\n",
    "\n",
    "txt_col_of_interest=['project_title','project_resource_summary',\n",
    "                     'project_essay_1','project_essay_2',\n",
    "                     'project_essay_3','project_essay_4',\n",
    "                     'project_subject_categories',\n",
    "                     'project_subject_subcategories']\n",
    "\n",
    "apps_rej_dict={}\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Note: we will label encode both the training and test set text variables.  This will serve to identify \n",
    "# repeated essays. all_projs_no_app is the dataframe we will use to do that.\n",
    "\n",
    "all_projs_no_app=get_all_data_without_approvals()\n",
    "\n",
    "for d in data_set:\n",
    "    timex.append_log_file('Starting: '+str(d))\n",
    "    \n",
    "    # Use basic_num_state_and_dummies file created above\n",
    "    \n",
    "    if d=='train':\n",
    "        df=pd.read_csv(__data_dir__+'1_num_state_no_dummies.csv')\n",
    "\n",
    "    elif d=='test':\n",
    "        df=pd.read_csv(__data_dir__+'should_fail_from_this_notebook.csv')\n",
    "    else:\n",
    "        timex.append_log_file('Disaster 1.  Neither train nor test')\n",
    "        \n",
    "    df.project_essay_3.fillna(' ',inplace=True)\n",
    "    df.project_essay_4.fillna(' ',inplace=True)\n",
    "    \n",
    "    timex.append_log_file(str(d)+' file loaded.')\n",
    "    \n",
    "    df['essay_sim']=df.apply((lambda x: check_essay_similarity\\\n",
    "      (x.project_essay_1,x.project_essay_2)),axis=1)\n",
    "    timex.append_log_file('Essay similarity done. '+str(len(df.columns))+\\\n",
    "                          ' total col')\n",
    "\n",
    "    for c in txt_col_of_interest:\n",
    "        all_projs_no_app[c].fillna(' ',inplace=True)\n",
    "        le.fit(all_projs_no_app[c])\n",
    "        df[c+'_label']=le.transform(df[c])\n",
    "\n",
    "        df[c+'_length']=df[c].apply(len)\n",
    "        df[c+'_cap_count']=df[c].apply(count_caps)\n",
    "        df[c+'cap_frac']=df[c+'_cap_count']/df[c+'_length']\n",
    "        df[c+'_uni_wrd_cnt']=df[c].apply(unique_words)\n",
    "        print c,'\\tLabel,length,cap_count, and unique words done.'\n",
    "        timex.append_log_file(c+' label, len, etc. complete.')\n",
    "        timex.get_elapsed_time(local_timer)\n",
    "        \n",
    "        df=get_column_polarity_and_subjectivity(df,c)\n",
    "        timex.append_log_file(c+' Pol/Subj done. '+\\\n",
    "                              timex.get_elapsed_time(local_timer))\n",
    "        \n",
    "        df[c+'_screened']=df.apply((lambda x: screen_ascii(df.loc[x.name,c])),axis=1)\n",
    "        df[c+'_screened']=df[c+'_screened'].apply(strip_string_punctuation)\n",
    "        df[c+'_screened']=df[c+'_screened'].apply(drop_stops_2)\n",
    "        \n",
    "        df[c+'_screened']=df[c+'_screened'].apply(' '.join)\n",
    "        \n",
    "        timex.append_log_file(c+' Screened/no stops')\n",
    "        timex.get_elapsed_time(local_timer)\n",
    "        \n",
    "        df[c+'_scr2'] = df.apply(lambda x: process_screened_text_for_tb_class\\\n",
    "          (df.loc[x.name,c+'_screened']),axis=1)\n",
    "        \n",
    "        df[c+'_scr2_misspell']=df.apply(lambda x: \\\n",
    "          spell_check_ntlk(df.loc[x.name,c+'_scr2'].split(' '),w2),axis=1)\n",
    "        \n",
    "        df[c+'_scr2_len']=df.apply(lambda x: \\\n",
    "          len(df.loc[x.name,c+'_scr2']),axis=1)\n",
    "        \n",
    "        df[c+'_scr2_wc']=df.apply(lambda x: \\\n",
    "          len(df.loc[x.name,c+'_scr2'].split(' ')),axis=1)\n",
    "        \n",
    "        df[c+'cap_wrd_frac']=df[c+'_cap_count']/df[c+'_scr2_wc']\n",
    "        \n",
    "        df[c+'_scr2_per_mis']=df.apply(lambda x: \\\n",
    "          round((df.loc[x.name,c+'_scr2_misspell']/(df.loc\\\n",
    "                 [x.name,c+'_scr2_wc']+.00000001)*1000/10.0),2),axis=1)\n",
    "        \n",
    "        def misspell_balance(number):\n",
    "            '''If all words mispelled, assume none are misspelled.'''\n",
    "            if number>=0.95:\n",
    "                return 0\n",
    "            return number\n",
    "        \n",
    "        df[c+'_scr2_per_mis']=df[c+'_scr2_per_mis'].apply(misspell_balance)\n",
    "        \n",
    "        \n",
    "        def frac_unique_wrds(string1):\n",
    "            '''Accept string, split, calc unique words.'''\n",
    "            tmp=string1.split(' ')\n",
    "            return round(float(len(set(tmp))/len(tmp)),4)\n",
    "        \n",
    "        df[c+'_scr2_frac_uni']= df[c+'_scr2'].apply(frac_unique_wrds)\n",
    "        \n",
    "        df.to_csv(__data_dir__+d+'_simple_txt_8_8.csv')\n",
    "        timex.quick_df_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before string check, df had:227 columns, after check: 200 columns\n",
      "Total test cases: 60087\n",
      "clf 0.848369863698\n",
      "Confusion Matrix for:  Gradient Boost\n",
      "\tActuals\n",
      "Pred.\t0\t1\t\tCorrect= 50976 \t\t0.848369863698\n",
      "0 \t253 \t158 \t\tFalse Negatives= 8953 \t0.00262952052857\n",
      "1 \t8953 \t50723 \t\tFalse Positives= 158 \t0.149000615774\n",
      "\n",
      "\n",
      "GB roc_aucscore_= 0.73101\n",
      "ranfor 0.830895201957\n",
      "Confusion Matrix for:  Random Forest\n",
      "\tActuals\n",
      "Pred.\t0\t1\t\tCorrect= 49926 \t\t0.830895201957\n",
      "0 \t1171 \t2126 \t\tFalse Negatives= 8035 \t0.0353820293907\n",
      "1 \t8035 \t48755 \t\tFalse Positives= 2126 \t0.133722768652\n",
      "\n",
      "\n",
      "RF roc_aucscore_= 0.65140\n",
      "Conditions simple text\n",
      "making graph\n",
      "#################\n",
      "       Feat_set        TP        TN        FP        FN       roc\n",
      "0           raw  0.846789  0.000000  0.153211  0.000000  0.500000\n",
      "1      numerics  0.846772  0.000000  0.153211  0.000017  0.592839\n",
      "2   state_costs  0.846706  0.000100  0.153111  0.000083  0.697778\n",
      "3  simple_text5  0.844159  0.004211  0.149001  0.002630  0.731009 \n",
      "\n",
      "\n",
      "       Feat_set        TP        TN        FP        FN       roc\n",
      "0           raw  0.846789  0.000000  0.153211  0.000000  0.500000\n",
      "1      numerics  0.796445  0.011933  0.141278  0.050344  0.535634\n",
      "2   state_costs  0.808444  0.014895  0.138316  0.038344  0.619028\n",
      "3  simple_text5  0.811407  0.019488  0.133723  0.035382  0.651404\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEJCAYAAACUk1DVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYJt3egAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets save the simple test files.\n",
    "\n",
    "# Save the working_file with and without dummie for later analysis.  \n",
    "df_dum=pd.get_dummies(work2_df, prefix='D_', columns=['1st_cat','project_grade_category',\n",
    "                                                             'teacher_prefix','school_state'])\n",
    "\n",
    "df_dum.to_csv(__data_dir__+'simple_text_w_dumies.csv',index=False)\n",
    "df.to_csv(__data_dir__+'simple_text_no_dummies.csv',index=False)\n",
    "\n",
    "# Check the impact of adding simple text features\n",
    "\n",
    "GB_con,rocky_gb,RF_con,rocky_rf=check_con_mat_progress(df)\n",
    "\n",
    "rf_results=pd.read_csv(__data_dir__+'rf_basic_results.csv',index_col=0)\n",
    "gb_results=pd.read_csv(__data_dir__+'gb_basic_results.csv',index_col=0)\n",
    "check_con_mat_progress\n",
    "print 'Conditions simple text'\n",
    "conditions='simple_text5'\n",
    "gb_results=add_con_mat_results(gb_results,conditions,GB_con,rocky_gb)\n",
    "rf_results=add_con_mat_results(rf_results,conditions,RF_con,rocky_rf)\n",
    "\n",
    "\n",
    "print 'making graph'\n",
    "total=GB_con.sum()\n",
    "gb_tmp=gb_results.copy()\n",
    "rf_tmp=rf_results.copy()\n",
    "col_tf=['TP','TN','FP','FN']\n",
    "for c in col_tf:\n",
    "    gb_tmp[c]=gb_tmp[c]/total\n",
    "    rf_tmp[c]=rf_tmp[c]/total\n",
    "    \n",
    "print '#################\\n',gb_tmp.head(10),'\\n\\n'\n",
    "print rf_tmp.head(10)\n",
    "\n",
    "\n",
    "plot_model_results(gb_tmp,'GB','lightgreen','darkgreen','palegreen','seagreen')\n",
    "plot_model_results(rf_tmp,'RF','lightcoral','darkred','firebrick','indianred')\n",
    "plt.title('Model performance through '+gb_tmp.Feat_set[len(gb_tmp.index)-1])\n",
    "plt.legend(loc='best',ncol=2)\n",
    "plt.show()\n",
    "\n",
    "rf_results.to_csv(__data_dir__+'rf_basic_results.csv')\n",
    "gb_results.to_csv(__data_dir__+'gb_basic_results.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Bill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Have loaded 179 stop words\n",
      "Have loaded Brown Corpus\n",
      "Have loaded Wornet Corpusas wn\n"
     ]
    }
   ],
   "source": [
    "# Run all below\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "#from nltk.corpus import words as wordnet  Can be removed after debug        \n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "print 'Have loaded {} stop words'.format(len(stopwords))\n",
    "print 'Have loaded Brown Corpus'\n",
    "print 'Have loaded Wornet Corpusas wn'\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "\n",
    "import my_watch as timex\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "import sklearn.feature_selection as feature_selection\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap as Basemap\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.cm import ScalarMappable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  My variables\n",
    "#__computer__='laptop'\n",
    "__computer__='desktop'\n",
    "\n",
    "if __computer__=='laptop':\n",
    "    __data_dir__=\"C:\\\\Users\\\\bill_\\\\Capstone 2\\\\Data\\\\\"\n",
    "    \n",
    "if __computer__=='desktop':\n",
    "    #__data_dir__=\"C:\\\\Users\\\\bill_\\\\OneDrive\\\\Donors Choose\\\\\"  \n",
    "    __data_dir__=\"C:\\\\Users\\\\Bill\\\\Capstone2\\\\Data\\\\\"\n",
    "    \n",
    "__train_file__=\"train.csv\"\n",
    "__test_file__=\"test.csv\"\n",
    "__resource_file__=\"resources.csv\"\n",
    "__cost_bin__=250\n",
    "__non_model_columns__=['teacher_id','project_submitted_datetime','project_subject_subcategories',\\\n",
    "                       u'project_title', u'project_essay_1', u'project_essay_2',\\\n",
    "                       u'project_essay_3', u'project_essay_4',\\\n",
    "                       u'project_resource_summary','project_subject_categories',\\\n",
    "                      'proj_id'] #use derived month\n",
    "\n",
    "\n",
    "__columns_for_dummies__=['first_cat','project_grade_category','teacher_prefix','school_state']\n",
    "\n",
    "random_state=0\n",
    "random_state_tts=42\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "#Create Compare Dictionary\n",
    "word_list=brown.words()\n",
    "word_list2=wn.words()\n",
    "word_set=set(word_list)\n",
    "\n",
    "w2=word_set.union(set(word_list2))\n",
    "word_list=[] #release memory\n",
    "word_list2=[] #release memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare test file\n",
    "# Generate all required info in this block\n",
    "# Use both train and test data to count current projects\n",
    "# Adjustment made to merge on 'Outer'\n",
    "\n",
    "# Second Meta Data Analysis\n",
    "\n",
    "def get_all_data_without_approvals():\n",
    "    '''Build simple df for counting all current submissions without \n",
    "    approval column.  Prevents using info you do not know.'''\n",
    "    tmp=pd.read_csv(__data_dir__+'train.csv')\n",
    "    print 'train length',len(tmp.id)\n",
    "    tmp=tmp.drop('project_is_approved',axis=1)\n",
    "    tmp1=pd.read_csv(__data_dir__+'test.csv')\n",
    "    print 'test length',len(tmp1.id)\n",
    "    tmp=tmp.append(tmp1)\n",
    "    print 'total_length',len(tmp.id)\n",
    "    tmp1=[] #release memory\n",
    "    return tmp\n",
    "\n",
    "def get_teacher_current_projects(df,all_projs_no_app):\n",
    "    '''Count the current projects for a teacher'''\n",
    "    tmp=all_projs_no_app.copy()\n",
    "    tmp1=tmp.pivot_table(index=['teacher_id'],values=['id'],aggfunc='count')\n",
    "    tmp1['teacher_id']=tmp1.index\n",
    "    tmp1=tmp1.rename(columns={'id':'currents'})\n",
    "    #how=left\n",
    "    df=df.merge(tmp1,on='teacher_id',how='left')\n",
    "    tmp=[] #release memory\n",
    "    tmp1=[]\n",
    "    return df\n",
    "\n",
    "def get_known_teacher_approval_rates(train_df, df):\n",
    "    '''call get_known_teacher_approval_rates(train_df,df) return df with extra column'''\n",
    "    tmp=train_df.copy()\n",
    "    tmp1=tmp.pivot_table(index='teacher_id',values=['project_is_approved'],aggfunc='mean')\n",
    "    tmp1['teacher_id']=tmp1.index\n",
    "    tmp1=tmp1.rename(columns={'project_is_approved':'teach_app_rate'})\n",
    "    tmp1['teach_app_rate']=tmp1.apply(lambda x: round(x.teach_app_rate,3),axis=1)\n",
    "    #df=pd.merge(df,tmp1,on='teacher_id',how='left')\n",
    "    df=pd.merge(df,tmp1,on='teacher_id',how='left')\n",
    "    tmp1=[]\n",
    "    tmp=[]\n",
    "    return df\n",
    "\n",
    "def check_nans(thing):\n",
    "    if math.isnan(thing):\n",
    "        return 0.85555\n",
    "    return thing\n",
    "\n",
    "def get_state_approval_rates(train_df, df):\n",
    "    '''call get_state_approval_rates(train_df,df) return df with extra column'''\n",
    "    tmp=train_df.copy()\n",
    "    tmp1=tmp.pivot_table(index='school_state',values=['project_is_approved'],aggfunc='mean')\n",
    "    tmp1['school_state']=tmp1.index\n",
    "    tmp1=tmp1.rename(columns={'project_is_approved':'state_app_rate'})\n",
    "    tmp1['state_app_rate']=tmp1.apply(lambda x: round(x.state_app_rate,3),axis=1)\n",
    "    df=df.merge(tmp1,on='school_state',how='left')\n",
    "    tmp1=[]\n",
    "    tmp=[]\n",
    "    return df\n",
    "\n",
    "def get_proj_costs3(df):\n",
    "    '''\n",
    "    Call: new_df=get_proj_costs2(df) return df with columns appended for \n",
    "    project costs, number of items, avg cost of items, max item cost\n",
    "    \n",
    "    '''\n",
    "    # Project Costs\n",
    "    tmp=get_resources_file()\n",
    "    tmp_df=tmp.copy()\n",
    "    tmp_df['proj_cost']=tmp_df['quantity']*tmp_df['price']\n",
    "    tmp_costs=tmp_df.pivot_table(index='id',values='proj_cost',aggfunc='sum')\n",
    "    tmp_costs['id']=tmp_costs.index\n",
    "    df=df.merge(tmp_costs,on='id')\n",
    "    tmp_df=[]\n",
    "    tmp_costs=[]\n",
    "    \n",
    "    # Average State Project Cost\n",
    "    state_costs=df.pivot_table(index='school_state',values='proj_cost',aggfunc='mean')\n",
    "    state_costs['school_state']=state_costs.index\n",
    "    state_costs=state_costs.rename(columns={'proj_cost':'avg_st_proj_cost'})\n",
    "    df=df.merge(state_costs,on='school_state')\n",
    "    df['avg_st_proj_cost']=df.apply(lambda x: round(x.avg_st_proj_cost,3),axis=1)\n",
    "    state_costs=[]\n",
    "    \n",
    "    # Cost Deltas\n",
    "    df['cost_delta']=df['avg_st_proj_cost']-df['proj_cost']\n",
    "    df['cost_delta']=df.apply(lambda x: round(x.cost_delta,2),axis=1)\n",
    "    \n",
    "    print 'Proj Costs Done'\n",
    "    \n",
    "    #Qty\n",
    "    tmp_items=tmp.pivot_table(index='id',values='quantity',aggfunc='sum')\n",
    "    tmp_items['id']=tmp_items.index\n",
    "    df=df.merge(tmp_items,on='id')\n",
    "    tmp_items=[]\n",
    "    \n",
    "    # Average State Items\n",
    "    state_qty=df.pivot_table(index='school_state',values='quantity',aggfunc='mean')\n",
    "    state_qty['school_state']=state_qty.index\n",
    "    state_qty=state_qty.rename(columns={'quantity':'avg_st_items'})\n",
    "    df=df.merge(state_qty,on='school_state')\n",
    "    df['avg_st_items']=df.apply(lambda x: round(x.avg_st_items,1),axis=1)\n",
    "    state_qty=[]\n",
    "    \n",
    "    # Cost Deltas\n",
    "    #df['qty_delta']=df['avg_st_items']-df['quantity']\n",
    "    #df['qty_delta']=df.apply(lambda x: round(x.qty_delta,1),axis=1)\n",
    "    \n",
    "    print 'Qtys Done'\n",
    "    \n",
    "    # Max Item Price\n",
    "    tmp_price=tmp.pivot_table(index='id',values='price',aggfunc='max')\n",
    "    tmp_price['id']=tmp_price.index\n",
    "    tmp_price=tmp_price.rename(columns={'price':'max_item_price'})\n",
    "    df=df.merge(tmp_price,on='id')\n",
    "    tmp_price=[]\n",
    "    \n",
    "    # Average State Max Price\n",
    "    state_price=df.pivot_table(index='school_state',values='max_item_price',aggfunc='mean')\n",
    "    state_price['school_state']=state_price.index\n",
    "    state_price=state_price.rename(columns={'max_item_price':'st_mx_item'})\n",
    "    df=df.merge(state_price,on='school_state')\n",
    "    df['st_mx_item']=df.apply(lambda x: round(x.st_mx_item,2),axis=1)\n",
    "    state_price=[]\n",
    "    \n",
    "   # df['max_price_delta']=df['st_mx_item']-df['max_item_price']\n",
    "   # df['max_price_delta']=df.apply(lambda x: round(x.qty_delta,2),axis=1)\n",
    "    \n",
    "    print 'Max Prices done'\n",
    "    \n",
    "    # Avg Item Price\n",
    "    tmp_price=tmp.pivot_table(index='id',values='price',aggfunc='mean')\n",
    "    tmp_price['id']=tmp_price.index\n",
    "    tmp_price=tmp_price.rename(columns={'price':'avg_item_price'})\n",
    "    df=df.merge(tmp_price,on='id')\n",
    "    df['avg_item_price']=df.apply(lambda x: round(x.avg_item_price,2),axis=1)\n",
    "    tmp_price=[]\n",
    "    \n",
    "    # Average State Max Price\n",
    "    state_price=df.pivot_table(index='school_state',values='avg_item_price',aggfunc='mean')\n",
    "    state_price['school_state']=state_price.index\n",
    "    state_price=state_price.rename(columns={'avg_item_price':'st_avg_item'})\n",
    "    df=df.merge(state_price,on='school_state')\n",
    "    df['st_avg_item']=df.apply(lambda x: round(x.st_avg_item,2),axis=1)\n",
    "    state_price=[]\n",
    "    \n",
    "    #df['avg_price_delta']=df['st_avg_item']-df['avg_item_price']\n",
    "    #df['avg_price_delta']=df.apply(lambda x: round(x.qty_delta,2),axis=1)\n",
    "    print 'Avg Prices done'\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_proj_costs4(df):\n",
    "    '''\n",
    "    Call: new_df=get_proj_costs2(df) return df with columns appended for \n",
    "    project costs, number of items, avg cost of items, max item cost\n",
    "    \n",
    "    '''\n",
    "    # Project Costs\n",
    "    tmp=get_resources_file()\n",
    "    tmp_df=tmp.copy()\n",
    "    tmp_df['proj_cost']=tmp_df['quantity']*tmp_df['price']\n",
    "    tmp_costs=tmp_df.pivot_table(index='id',values='proj_cost',aggfunc='sum')\n",
    "    tmp_costs['id']=tmp_costs.index\n",
    "    df=df.merge(tmp_costs,on='id')\n",
    "    tmp_df=[]\n",
    "    tmp_costs=[]\n",
    "    \n",
    "    # Average State Project Cost\n",
    "    state_costs=df.pivot_table(index='school_state',values='proj_cost',aggfunc='mean')\n",
    "    state_costs['school_state']=state_costs.index\n",
    "    state_costs=state_costs.rename(columns={'proj_cost':'avg_st_proj_cost'})\n",
    "    df=df.merge(state_costs,on='school_state')\n",
    "    df['avg_st_proj_cost']=df.apply(lambda x: round(x.avg_st_proj_cost,3),axis=1)\n",
    "    state_costs=[]\n",
    "    \n",
    "    # Cost Deltas\n",
    "    df['cost_delta']=df['avg_st_proj_cost']-df['proj_cost']\n",
    "    df['cost_delta']=df.apply(lambda x: round(x.cost_delta,2),axis=1)\n",
    "\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# My methods\n",
    "\n",
    "def get_raw_training_file():\n",
    "    return pd.read_csv(__data_dir__+__train_file__)\n",
    "\n",
    "def get_raw_test_file():\n",
    "    return pd.read_csv(__data_dir__+__test_file__)\n",
    "\n",
    "def get_resources_file():\n",
    "    return pd.read_csv(__data_dir__+__resource_file__)\n",
    "\n",
    "def get_range(column):\n",
    "    '''Accept one column of DF return tuple with max,min'''\n",
    "    return (column.min(),column.max())\n",
    "\n",
    "def get_barplot_parameters(num_bins, df, bin_size=5):\n",
    "    '''Accept number of bins, bin_size, df'''\n",
    "    \n",
    "    lower=[]\n",
    "    upper=[]\n",
    "    appd=[]\n",
    "    rejd=[]\n",
    "    totl=[]\n",
    "    per_rej=[]\n",
    "    per_app=[]\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(num_bins):\n",
    "        low=i*5\n",
    "        high=(i+1)*5\n",
    "        tmp=df.loc[(df.total>=low)&(df.total<high),['rejected','approved','total']]\n",
    "        lower.append(low)\n",
    "        upper.append(high)\n",
    "        rejd.append(tmp.rejected.sum())\n",
    "        appd.append(tmp.approved.sum())\n",
    "        totl.append(tmp.total.sum())\n",
    "        per_rej.append(float(tmp.rejected.sum())/tmp.total.sum())\n",
    "        per_app.append(float(tmp.approved.sum())/tmp.total.sum())\n",
    "    \n",
    "    return lower,upper,appd, rejd, totl, per_rej, per_app\n",
    "    \n",
    "def add_month_column(df):\n",
    "    '''Accept a df with strings in the datetime submitted column,\n",
    "    return df with column converted to datetime and a month column added'''\n",
    "    #Convert project_submitted_datetime from string to pandas timestamp\n",
    "    #print df.head()\n",
    "    df['project_submitted_datetime'] =  pd.to_datetime(df['project_submitted_datetime'],\\\n",
    "                                                       infer_datetime_format=True)\n",
    "    df['month']=df.apply((lambda x: x.project_submitted_datetime.month),axis=1)\n",
    "    return df\n",
    "\n",
    "def make_a_map(min,max,state_mapping_dict,title,map_colors='Reds_r'):\n",
    "    '''Accept max,min, states mapping which is a dictionary with state keys and map values as items,title and colors, \n",
    "    then draws a relative map.  Colors default to reds, with max values being dark'''\n",
    "\n",
    "    map_min=float(min)\n",
    "    map_max=float(max)\n",
    "\n",
    "    # Look at states, define iterable of unique states, establish two letter dict\n",
    "    \n",
    "    states = {'AK': 'Alaska','AL': 'Alabama','AR': 'Arkansas','AS': 'American Samoa','AZ': 'Arizona','CA': 'California',\n",
    "        'CO': 'Colorado',\n",
    "        'CT': 'Connecticut','DC': 'District of Columbia','DE': 'Delaware','FL': 'Florida','GA': 'Georgia',\n",
    "        'GU': 'Guam','HI': 'Hawaii','IA': 'Iowa','ID': 'Idaho','IL': 'Illinois',\n",
    "        'IN': 'Indiana','KS': 'Kansas','KY': 'Kentucky','LA': 'Louisiana',\n",
    "        'MA': 'Massachusetts','MD': 'Maryland','ME': 'Maine','MI': 'Michigan',\n",
    "        'MN': 'Minnesota','MO': 'Missouri','MP': 'Northern Mariana Islands','MS': 'Mississippi','MT': 'Montana',\n",
    "        'NA': 'National','NC': 'North Carolina','ND': 'North Dakota','NE': 'Nebraska','NH': 'New Hampshire',\n",
    "        'NJ': 'New Jersey','NM': 'New Mexico','NV': 'Nevada','NY': 'New York','OH': 'Ohio','OK': 'Oklahoma',\n",
    "        'OR': 'Oregon','PA': 'Pennsylvania','PR': 'Puerto Rico','RI': 'Rhode Island','SC': 'South Carolina',\n",
    "        'SD': 'South Dakota','TN': 'Tennessee','TX': 'Texas','UT': 'Utah','VA': 'Virginia','VI': 'Virgin Islands',\n",
    "        'VT': 'Vermont','WA': 'Washington','WI': 'Wisconsin','WV': 'West Virginia','WY': 'Wyoming'}\n",
    "    \n",
    "    \n",
    "    # Lambert Conformal map of lower 48 states.\n",
    "    m = Basemap(llcrnrlon=-119,llcrnrlat=22,urcrnrlon=-64,urcrnrlat=49,\n",
    "            projection='lcc',lat_1=33,lat_2=45,lon_0=-95)\n",
    "    # draw state boundaries.\n",
    "    if __computer__=='laptop':\n",
    "        shp_info = m.readshapefile('c:\\\\users\\\\bill_\\st99_d00','states',drawbounds=True)\n",
    "    if __computer__=='desktop':\n",
    "        shp_info = m.readshapefile('c:\\\\users\\\\bill\\st99_d00','states',drawbounds=True)\n",
    "\n",
    "    colors={}\n",
    "    statenames=[]\n",
    "  \n",
    "    if map_colors==\"Summer\":  #\"\"Blues_r\":\n",
    "        cmap = plt.cm.Blues_r# hot # use 'hot' colormap\n",
    "        \n",
    "    else:\n",
    "        cmap = plt.cm.Reds_r# hot # use 'hot' colormap\n",
    "\n",
    "    vmin = map_min; vmax = map_max\n",
    "\n",
    "    for shapedict in m.states_info:\n",
    "        statename = shapedict['NAME']\n",
    "        # skip DC and Puerto Rico.\n",
    "        if statename not in ['District of Columbia','Puerto Rico']:\n",
    "            pop = state_mapping_dict[states.keys()[states.values().index(statename)]]             ###statename]\n",
    "            # calling colormap with value between 0 and 1 returns\n",
    "            # rgba value.  Invert color range (hot colors are high\n",
    "            # population), take sqrt root to spread out colors more.\n",
    "            #colors[statename] = cmap( 1.-np.sqrt((float(pop)-vmin)/(vmax-vmin)))[:3]\n",
    "            colors[statename] = cmap(pop)[:3]\n",
    "        statenames.append(statename)\n",
    "    # cycle through state names, color each one.\n",
    "    ax = plt.gca() # get current axes instance\n",
    "    for nshape,seg in enumerate(m.states):\n",
    "        # skip DC and Puerto Rico.\n",
    "        if statenames[nshape] not in ['District of Columbia','Puerto Rico']:\n",
    "            color = rgb2hex(colors[statenames[nshape]]) \n",
    "            poly = Polygon(seg,facecolor=color,edgecolor=color)\n",
    "            ax.add_patch(poly)\n",
    "\n",
    "    ay=plt.gca()\n",
    "    \n",
    "    mapper = ScalarMappable(cmap=cmap)\n",
    "    a=np.array(state_mapping_dict.values()).astype(np.float)\n",
    "    a[0]=map_min\n",
    "    a[len(a)-1]=map_max #Force standard scales across all plots\n",
    "    mapper.set_array(a)\n",
    "    plt.colorbar(mapper, shrink=0.65)\n",
    "    plt.title(title)\n",
    "\n",
    "    return ay\n",
    "\n",
    "def get_1st_proj_sub_cat(df):\n",
    "    '''Accept df, separate out first subject categry and return the df'''\n",
    "\n",
    "    def get_cat_one(cat):\n",
    "        nc=cat.split(',')\n",
    "        nc[0]=nc[0].strip(' ')\n",
    "        return nc[0]\n",
    "\n",
    "    df['1st_cat']=df.project_subject_categories.apply(get_cat_one)\n",
    "    return df\n",
    "\n",
    "def cat_size(cat):\n",
    "    nc=cat.split(',')\n",
    "    return len(nc)\n",
    "\n",
    "def var_rej_an(feature_df,variable,variable_labels=False):\n",
    "    plt.figure(figsize=(10,3),dpi=100)\n",
    "    plt.subplot(1,2,1)\n",
    "    \n",
    "    # Check for 'id' column and reset locally to proj_id\n",
    "    try:\n",
    "        feature_df.rename(columns={'id': 'proj_id'}, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    this_indy=get_rej_stats(feature_df,variable)\n",
    "    plt.subplot(1,2,2)\n",
    "    get_barplot(this_indy,variable,variable_labels)\n",
    "    plt.suptitle(variable,verticalalignment='top',x=0.5, y=1.05)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return this_indy\n",
    "\n",
    "def get_rej_stats(train_df,index_name):\n",
    "    '''Accept the training_df and variable of interest and return\n",
    "    a pivot table that can be used for CDF creation'''\n",
    "    pv_df=train_df.pivot_table(index=index_name,columns=['project_is_approved'],\\\n",
    "                                values='proj_id',aggfunc='count')\n",
    "    pv_df.fillna(0,inplace=True)\n",
    "\n",
    "    pv_df.rename(columns={0.0: 'rejected', 1.0: 'approved'}, inplace=True)\n",
    "\n",
    "    pv_df['total']=pv_df['rejected']+pv_df['approved']\n",
    "    pv_df['rej_rat']=pv_df['rejected']/pv_df['total']\n",
    "\n",
    "    if index_name=='month':\n",
    "        pv_df['month']=pv_df.index\n",
    "        pv_df.sort_values('month',ascending=True,inplace=True)\n",
    "        \n",
    "    elif index_name=='teacher_number_of_previously_posted_projects':\n",
    "        pv_df['exp']=pv_df.index\n",
    "        pv_df.sort_values('exp',ascending=True,inplace=True)\n",
    "        \n",
    "    else:\n",
    "        pv_df.sort_values('rejected',ascending=False,inplace=True)\n",
    "        \n",
    "    pv_df['rol_sum']=pv_df.rejected.cumsum()\n",
    "    \n",
    "    num_rejected=pv_df.rejected.sum()\n",
    "    pv_df['cum_rej_share']=pv_df.rol_sum/num_rejected\n",
    "    \n",
    "    num_things=pv_df.total.sum()\n",
    "    pv_df['tot_pros_share']=pv_df['total'].cumsum()/float(num_things)\n",
    "    \n",
    "    xs=[float(x)/num_things for x in range(1,len(pv_df.cum_rej_share)+1)]\n",
    "    \n",
    "    flag_50=0\n",
    "    flag_90=0\n",
    "    x_count=0\n",
    "    \n",
    "    for l in pv_df.index:\n",
    "        if flag_50==0:\n",
    "            \n",
    "            if pv_df.loc[l,'cum_rej_share']>=0.5:\n",
    "                x_50=xs[x_count]\n",
    "                y_50=pv_df.loc[l,'cum_rej_share']\n",
    "                flag_50=1\n",
    "                \n",
    "        if (flag_50==1) & (flag_90==0):\n",
    "            if pv_df.loc[l,'cum_rej_share']>=0.9:\n",
    "                x_90=xs[x_count]\n",
    "                y_90=pv_df.loc[l,'cum_rej_share']\n",
    "                flag_90=1\n",
    "                \n",
    "        x_count+=1\n",
    "    \n",
    "    plt.ylim(0,1.05)\n",
    "    xpoints=list(pv_df.index)\n",
    "    \n",
    "    if len(xs)>25:\n",
    "        stoppoint=len(xs)/3+1\n",
    "        plt.xlim(0,xs[stoppoint])\n",
    "        \n",
    "        xpoints=[]\n",
    "        x_count=0\n",
    "        for x in pv_df.index:\n",
    "            if x_count%3==0:\n",
    "                xpoints.append(x)\n",
    "            else:\n",
    "                xpoints.append('')\n",
    "            x_count+=1\n",
    "        \n",
    "\n",
    "    plt.xticks(xs,xpoints,rotation=45)\n",
    "\n",
    "    plt.yticks([0.0,0.2,0.4,0.6,0.8,1.0])\n",
    "    plt.plot(xs,pv_df.cum_rej_share,color='b',label='Total Rejection Share')\n",
    "    plt.plot(xs,pv_df.tot_pros_share,color='c',label='Total Proposal Share')\n",
    "    plt.plot([0,x_90],[y_90,y_90],color='r',linestyle='dotted',label='50/90% levels')\n",
    "    plt.plot([x_90,x_90],[0,y_90],color='r',linestyle='dotted')\n",
    "    plt.plot([0,x_50],[y_50,y_50],color='r',linestyle='dotted')\n",
    "    plt.plot([x_50,x_50],[0,y_50],color='r',linestyle='dotted')\n",
    "    \n",
    "    plt.xlim(0,xs[-1])\n",
    "    \n",
    "    if(index_name=='teacher_number_of_previously_posted_projects'):\n",
    "        plt.xlim(0,xs[80])\n",
    "    if(index_name=='cost_bins'):\n",
    "        plt.xlim(0,xs[8])\n",
    "    if(index_name=='project_subject_categories'):\n",
    "        plt.xlim(0,xs[8])\n",
    "    if(index_name=='project_grade_category'):\n",
    "        plt.xlim(0,xs[3])\n",
    "        \n",
    "    plt.legend(loc='lower right')\n",
    "    #plt.show()\n",
    "    \n",
    "    return pv_df\n",
    "\n",
    "def big_picture_plot(raw_train_df,variable,title):\n",
    "    '''Generate a big simple barplot for initial examination of meta data'''\n",
    "    \n",
    "    sns.set(style=\"whitegrid\")\n",
    "\n",
    "    # Initialize the matplotlib figure\n",
    "    #f, ax = plt.subplots(figsize=(11, 4)) \n",
    "\n",
    "    # Load the raw proposed project dataset\n",
    "    projects = raw_train_df.pivot_table(index=variable,columns='project_is_approved',\n",
    "                                       values='id',aggfunc='count')\n",
    "    \n",
    "    projects=projects.rename(columns={0:'rejected',1:\"approved\"})\n",
    "    projects['total']=projects['rejected']+projects['approved']\n",
    "    projects['indy']=projects.index\n",
    "    projects.sort_values('total',ascending=False,inplace=True)\n",
    "    \n",
    "    \n",
    "    if len(projects.total)>=25:\n",
    "        projects=projects.loc[projects.index[:25],:]\n",
    "        \n",
    "    # Plot the total projects\n",
    "    sns.set_color_codes(\"pastel\")\n",
    "    sns.barplot(y=\"total\", x='indy', data=projects, \n",
    "                label=\"Total\", color=\"b\")\n",
    "    sns.barplot(y=\"approved\", x='indy',data=projects,\n",
    "                label=\"Approved\", color=\"c\")\n",
    "    sns.barplot(y=\"rejected\", x='indy',data=projects,\n",
    "                label=\"Rejected\", color=\"r\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylabel('Occurences')\n",
    "    plt.xlabel('')\n",
    "    plt.ylim(0,int(projects['total'].max()*1.1))\n",
    "    plt.title(title)\n",
    "    #plt.show()\n",
    "    \n",
    "def get_barplot(this_indy,variable,variable_labels=False):\n",
    "    '''accept the df for the variable of interest'''\n",
    "    this_indy.sort_values('total',ascending=False,inplace=True)\n",
    "    rej_ratio=float(this_indy.rejected.sum())/this_indy.total.sum()\n",
    "    targets=np.multiply(this_indy.total,rej_ratio)\n",
    "\n",
    "    tmp=this_indy.rejected-targets\n",
    "    tmp2=tmp.copy()\n",
    "    tmp2[tmp2<0]=0\n",
    "    tmp3=tmp.copy()\n",
    "    tmp3[tmp3>=0]=0\n",
    "\n",
    "    axis_length=10\n",
    "    if len(this_indy.index)<10:\n",
    "        axis_length=len(this_indy.index)\n",
    "    \n",
    "    sns.barplot(x=this_indy.index[:axis_length],y=this_indy.rejected[:axis_length],color='b',label='Total Rej')\n",
    "    sns.barplot(x=this_indy.index[:axis_length],y=tmp2[:axis_length],color='r',label='Excess Rej.')\n",
    "    sns.barplot(x=this_indy.index[:axis_length],y=tmp3[:axis_length],color='y',label='Excess App')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylim(-1500,10000)\n",
    "    plt.ylabel('Occurences')\n",
    "    plt.xticks(range(axis_length),rotation=45)\n",
    "    #plt.title('Excess Rejections for ',var_of_int)\n",
    "    #plt.xlabel(variable)\n",
    "    plt.tick_params(labelbottom=variable_labels)\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    return\n",
    "\n",
    "def get_proj_costs(df):\n",
    "    '''\n",
    "    May Need debug or call version 2 which changed name\n",
    "    Get project costs and add column to df referenced off project id.\n",
    "    Action are open raw training file, merge resources, make dict of costs,\n",
    "    apply those costs to the dict under consideration.  \n",
    "    \n",
    "    Note:  also grab test file so dict is complete for when we build model.'''\n",
    "    full_costs_df=get_raw_training_file()\n",
    "    full_costs_df.drop('project_is_approved',axis=1,inplace=True)\n",
    "    full_costs_df2=get_raw_test_file()\n",
    "    full_costs_df.append(full_costs_df2)\n",
    "    tmp=get_resources_file()\n",
    "    \n",
    "    full_costs_df=full_costs_df.merge(tmp,on='id', how='left')\n",
    "    full_costs_df['proj_cost1']=full_costs_df['quantity']*full_costs_df['price']\n",
    "    proj_costs=full_costs_df.pivot_table(index='id',values='proj_cost1',aggfunc='sum')\n",
    "    proj_cost_dict=proj_costs.to_dict()\n",
    "    full_costs_df['proj_cost']=df.apply((lambda x: proj_cost_dict['proj_cost1'][x.proj_id]),axis=1)\n",
    "    pc_range=get_range(full_costs_df['proj_cost'].values)\n",
    "    print 'Range of Project costs:', pc_range\n",
    "    full_costs_df['cost_bin']=df.apply((lambda x: int(x.proj_cost/__cost_bin__)*__cost_bin__),axis=1)\n",
    "    full_costs_df.drop('proj_cost1',inplace=True,axis=1)\n",
    "    return full_costs_df\n",
    "\n",
    "def get_proj_costs_for_df(df):\n",
    "    '''\n",
    "    Add project costs to a random df.'''\n",
    "    full_costs_df=df.copy()\n",
    "\n",
    "    tmp=get_resources_file()\n",
    "    tmp['line_cost']=tmp['quantity']*tmp['price']\n",
    "    proj_costs=tmp.pivot_table(index='id',values='line_cost',aggfunc='sum')\n",
    "    proj_costs.reset_index(drop=False,inplace=True)\n",
    "    proj_costs.rename(columns={'id':'proj_id','line_cost':'proj_cost'},inplace=True)\n",
    "    df.rename(columns={'id':'proj_id'},inplace=True)\n",
    "    df=df.merge(proj_costs,on='proj_id', how='left')\n",
    "    df['cost_bin']=df.apply((lambda x: int(x.proj_cost/__cost_bin__)*__cost_bin__),axis=1)\n",
    "    return df\n",
    "\n",
    "def get_proj_costs_state(df):\n",
    "    '''\n",
    "    Call: new_df=get_proj_costs2(df) return df with columns appended for \n",
    "    project costs, number of items, avg cost of items, max item cost\n",
    "    '''\n",
    "    \n",
    "    # Project Costs\n",
    "    \n",
    "    tmp=get_resources_file()\n",
    "    tmp.rename(columns={'id':'proj_id'},inplace=True)\n",
    "    tmp_df=tmp.copy()\n",
    "    tmp_df['proj_cost']=tmp_df['quantity']*tmp_df['price']            \n",
    "    tmp_costs=tmp_df.pivot_table(index='proj_id',values='proj_cost',aggfunc='sum')\n",
    "    tmp_costs['proj_id']=tmp_costs.index    \n",
    "\n",
    "    #df=pd.merge(df, tmp_costs, how='left', on=['proj_id']) commented out because we have project cost from before\n",
    "\n",
    "    del tmp_df,tmp_costs\n",
    "    \n",
    "    # Average State Project Cost\n",
    "\n",
    "    state_costs=df.pivot_table(index='school_state',values='proj_cost',aggfunc='mean')\n",
    "    state_costs['school_state']=state_costs.index\n",
    "    state_costs=state_costs.rename(columns={'proj_cost':'avg_st_proj_cost'})\n",
    "    #df=df.merge(state_costs,on='school_state',how='left')\n",
    "    df=pd.merge(df, state_costs, how='left', on=['school_state'])\n",
    "    print 'df looking for : avg_st_proj_cost',df.columns\n",
    "    \n",
    "    df['avg_st_proj_cost']=df.apply(lambda x: round(x.avg_st_proj_cost,3),axis=1)\n",
    "    state_costs=[]\n",
    "    \n",
    "    # Cost Deltas\n",
    "    df['cost_delta']=df['avg_st_proj_cost']-df['proj_cost']\n",
    "    df['cost_delta']=df.apply(lambda x: round(x.cost_delta,2),axis=1)\n",
    "    \n",
    "    #print 'Proj Costs Done'\n",
    "    \n",
    "    #Qty\n",
    "    tmp_items=tmp.pivot_table(index='proj_id',values='quantity',aggfunc='sum')\n",
    "    tmp_items['proj_id']=tmp_items.index\n",
    "    #df=df.merge(tmp_items,on='id')\n",
    "    df=pd.merge(df, tmp_items, how='left', on=['proj_id'])\n",
    "    del tmp_items\n",
    "    \n",
    "    # Average State Items\n",
    "    state_qty=df.pivot_table(index='school_state',values='quantity',aggfunc='mean')\n",
    "    state_qty['school_state']=state_qty.index\n",
    "    state_qty=state_qty.rename(columns={'quantity':'avg_st_items'})\n",
    "    #df=df.merge(state_qty,on='school_state',how='left')\n",
    "    df=pd.merge(df, state_qty, how='left', on=['school_state'])\n",
    "    \n",
    "    df['avg_st_items']=df.apply(lambda x: round(x.avg_st_items,1),axis=1)\n",
    "    del state_qty\n",
    "    \n",
    "    # Cost Deltas\n",
    "    df['qty_delta']=df['avg_st_items']-df['quantity']\n",
    "    df['qty_delta']=df.apply(lambda x: round(x.qty_delta,1),axis=1)\n",
    "    \n",
    "    #print 'Qtys Done'\n",
    "    \n",
    "    # Max Item Price\n",
    "    tmp_price=tmp.pivot_table(index='proj_id',values='price',aggfunc='max')\n",
    "    tmp_price['proj_id']=tmp_price.index\n",
    "    tmp_price=tmp_price.rename(columns={'price':'max_item_price'})\n",
    "    #df=df.merge(tmp_price,on='id',how='left')\n",
    "    df=pd.merge(df, tmp_price, how='left', on=['proj_id'])\n",
    "    del tmp_price\n",
    "    \n",
    "    # Average State Max Price\n",
    "    state_price=df.pivot_table(index='school_state',values='max_item_price',aggfunc='mean')\n",
    "    state_price['school_state']=state_price.index\n",
    "    state_price=state_price.rename(columns={'max_item_price':'st_mx_item'})\n",
    "    #df=df.merge(state_price,on='school_state')\n",
    "    df=pd.merge(df, state_price, how='left', on=['school_state'])\n",
    "    df['st_mx_item']=df.apply(lambda x: round(x.st_mx_item,2),axis=1)\n",
    "    \n",
    "    \n",
    "    df['max_price_delta']=df['st_mx_item']-df['max_item_price']\n",
    "    df['max_price_delta']=df.apply(lambda x: round(x.qty_delta,2),axis=1)\n",
    "    #print 'Max Prices done'\n",
    "    \n",
    "    # Min Item Price\n",
    "    tmp_price=tmp.pivot_table(index='proj_id',values='price',aggfunc='min')\n",
    "    tmp_price['proj_id']=tmp_price.index\n",
    "    tmp_price=tmp_price.rename(columns={'price':'min_item_price'})\n",
    "    tmp_price.min_item_price=tmp_price.min_item_price.apply(lambda x: 0.000001 if x == 0 else x)\n",
    "    #df=df.merge(tmp_price,on='id',how='left')\n",
    "    df=pd.merge(df, tmp_price, how='left', on=['proj_id'])\n",
    "    del tmp_price\n",
    "    \n",
    "    # Average State Min Price\n",
    "    state_price=df.pivot_table(index='school_state',values='min_item_price',aggfunc='mean')\n",
    "    state_price['school_state']=state_price.index\n",
    "    state_price=state_price.rename(columns={'min_item_price':'st_min_item'})\n",
    "    state_price.st_min_item=state_price.st_min_item.apply(lambda x: 0.000001 if x == 0 else x)\n",
    "    #df=df.merge(state_price,on='school_state')\n",
    "    df=pd.merge(df, state_price, how='left', on=['school_state'])\n",
    "    #df['st_min_item']=df.apply(lambda x: round(x.st_min_item,2),axis=1)\n",
    "    del state_price\n",
    "    \n",
    "    df['min_price_delta']=df['st_min_item']-df['min_item_price']\n",
    "    df['min_price_delta']=df.apply(lambda x: round(x.qty_delta,2),axis=1)\n",
    "    #print 'Min Prices done'\n",
    "    \n",
    "    # Avg Item Price\n",
    "    tmp_price=tmp.pivot_table(index='proj_id',values='price',aggfunc='mean')\n",
    "    tmp_price['proj_id']=tmp_price.index\n",
    "    tmp_price=tmp_price.rename(columns={'price':'avg_item_price'})\n",
    "    #df=df.merge(tmp_price,on='id',how='left')\n",
    "    df=pd.merge(df, tmp_price, how='left', on=['proj_id'])\n",
    "    \n",
    "    df['avg_item_price']=df.apply(lambda x: round(x.avg_item_price,2),axis=1)\n",
    "    del tmp_price\n",
    "    \n",
    "    # Average State Max Price\n",
    "    state_price=df.pivot_table(index='school_state',values='avg_item_price',aggfunc='mean')\n",
    "    state_price['school_state']=state_price.index\n",
    "    state_price=state_price.rename(columns={'avg_item_price':'st_avg_item'})\n",
    "    #df=df.merge(state_price,on='school_state',how='left')\n",
    "    df=pd.merge(df, state_price, how='left', on=['school_state'])\n",
    "    \n",
    "    df['st_avg_item']=df.apply(lambda x: round(x.st_avg_item,2),axis=1)\n",
    "    del state_price\n",
    "    \n",
    "    df['avg_price_delta']=df['st_avg_item']-df['avg_item_price']\n",
    "    df['avg_price_delta']=df.apply(lambda x: round(x.qty_delta,2),axis=1)\n",
    "    #print 'Avg Prices done'\n",
    "    \n",
    "    # Starting Ratios\n",
    "    #print 'Starting Ratios'\n",
    "    df['maxdmin']=df['max_item_price']/df['min_item_price']\n",
    "    df['maxdmin']=df.apply(lambda x: round(x.maxdmin,2),axis=1)\n",
    "    df['maxdavg']=df['max_item_price']/df['avg_item_price']\n",
    "    df['maxdavg']=df.apply(lambda x: round(x.maxdavg,2),axis=1)\n",
    "    df['maxdstmax']=df['max_item_price']/df['st_mx_item']\n",
    "    df['maxdstmax']=df.apply(lambda x: round(x.maxdstmax,2),axis=1)\n",
    "    df['avgdstavg']=df['avg_item_price']/df['st_avg_item']\n",
    "    df['avgdstavg']=df.apply(lambda x: round(x.avgdstavg,2),axis=1)\n",
    "    df['mindavg']=df['min_item_price']/df['avg_item_price']\n",
    "    df['mindavg']=df.apply(lambda x: round(x.mindavg,2),axis=1)\n",
    "    df['mindstmin']=df['min_item_price']/df['st_min_item']\n",
    "    df['mindstmin']=df.apply(lambda x: round(x.mindstmin,2),axis=1)\n",
    "    #print 'Done Ratios'\n",
    "    \n",
    "    try:\n",
    "        del tmp\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_currents_per_teacher(df):\n",
    "    '''Add a column that has current projects per teacher to DF'''\n",
    "\n",
    "    tmp2=df.groupby(['teacher_id'])['proj_id'].count()\n",
    "    tmp2=tmp2.to_frame()\n",
    "    tmp2['teacher_id']=tmp2.index\n",
    "    tmp2.rename(columns={'proj_id':'currents'},inplace=True)\n",
    "    df=df.merge(tmp2,on='teacher_id',how='left')\n",
    "    tmp2=''#release memory\n",
    "    return df\n",
    "\n",
    "def make_density_plot(df1,variable):\n",
    "    \n",
    "    teach_proj_df=df1.pivot_table(index=variable,columns='project_is_approved',values='proj_id',aggfunc='count')\n",
    "    teach_proj_df.fillna(0,inplace=True)\n",
    "    teach_proj_df.rename(columns={0:'rejected',1:\"approved\"},inplace=True)\n",
    "    teach_proj_df['total']=teach_proj_df['rejected']+teach_proj_df['approved']\n",
    "    teach_proj_df.sort_values(by='total',ascending=True,inplace=True)\n",
    "\n",
    "    #print variable+\" approved/rejected:\"\n",
    "    #print teach_proj_df.head(5)\n",
    "\n",
    "    teach_proj2=teach_proj_df.reset_index(drop=False)\n",
    "    teach_proj2=teach_proj2.pivot_table(index='total',values=['rejected','approved'],aggfunc='sum')\n",
    "    teach_proj2['total']=teach_proj2['rejected']+teach_proj2['approved']\n",
    "\n",
    "    teach_proj2['rej_rate']=teach_proj2['rejected']/teach_proj2['total']\n",
    "\n",
    "    t_app=teach_proj2.approved.sum()\n",
    "    t_rej=teach_proj2.rejected.sum()\n",
    "    t_tot=teach_proj2.total.sum()\n",
    "\n",
    "    teach_proj2['per_rej']=teach_proj2.rejected/float(t_rej)\n",
    "    teach_proj2['cdf_a']=teach_proj2.approved.cumsum()/float(t_app)\n",
    "    teach_proj2['cdf_r']=teach_proj2.rejected.cumsum()/float(t_rej)\n",
    "    teach_proj2['cdf_t']=teach_proj2.total.cumsum()/float(t_tot)\n",
    "\n",
    "    #print \"\\nSecond Pivot allows CDF and cum calculations\"\n",
    "    #print teach_proj2.head()\n",
    "    #print '\\nTail\\n',teach_proj2.tail()\n",
    "\n",
    "    plt.figure(figsize=(10,3),dpi=100)\n",
    "    \n",
    "    width=1\n",
    "    if teach_proj2.index.max()>100:\n",
    "        width=teach_proj2.index.max()/(len(teach_proj2.index)+1)\n",
    "    plt.bar(teach_proj2.index,teach_proj2.per_rej,width=width,color=\"r\",alpha=0.75,label=\"% Total Rejections\")\n",
    "    plt.plot(teach_proj2.index,teach_proj2.rej_rate,color=\"gray\", lineStyle=\"--\",label=\"Rejection Rate\")\n",
    "    plt.plot(teach_proj2.index,teach_proj2.cdf_a,color=\"orange\",label=\"CDF Approvals\")\n",
    "    plt.plot(teach_proj2.index,teach_proj2.cdf_r,color=\"r\",label=\"CDF Rejections\")\n",
    "    plt.plot(teach_proj2.index,teach_proj2.cdf_t,color=\"g\",label=\"CDF Totals\")\n",
    "    #plt.xlim(0,30)\n",
    "    plt.legend(loc='best')\n",
    "    plt.title(\"Rejections Analysis\")\n",
    "    plt.xlabel(\"Current Submissions/\"+variable)\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def print_con_matrix(what_model,con_mat):\n",
    "    '''Accept and print the confusion matrix in a friendly format'''\n",
    "    total=con_mat[0,0]+con_mat[0,1]+con_mat[1,0]+con_mat[1,1]\n",
    "    corr_per=float(con_mat[0,0]+con_mat[1,1])/total\n",
    "    fn_per=float(con_mat[1,0])/total\n",
    "    fp_per=float(con_mat[0,1])/total\n",
    "    print 'Confusion Matrix for: ',what_model\n",
    "    print '\\tActuals'\n",
    "    print 'Pred.\\t0\\t1\\t\\tCorrect=', con_mat[0,0]+con_mat[1,1],'\\t\\t',corr_per\n",
    "    print '0','\\t',con_mat[0,0],'\\t',con_mat[1,0], '\\t\\tFalse Negatives=',con_mat[0,1],'\\t',fn_per\n",
    "    print '1','\\t',con_mat[0,1],'\\t',con_mat[1,1], '\\t\\tFalse Positives=',con_mat[1,0],'\\t',fp_per\n",
    "    print '\\n'\n",
    "    return\n",
    "\n",
    "def get_textblob(item):\n",
    "    '''get TextBlob that is converted to utf-8 format'''\n",
    "    item=item.decode('utf-8')\n",
    "    tb=TextBlob(item)\n",
    "    return tb\n",
    "\n",
    "\n",
    "def get_title_polarity_and_subjectivity(df):\n",
    "    '''Add polarity and subjectivity columns for title to df, but do not yet drop\n",
    "    title column.'''\n",
    "\n",
    "    polar=[]\n",
    "    subj=[]\n",
    "    for t in df.project_title:\n",
    "        b=get_textblob(t)\n",
    "        polar.append(b.polarity)\n",
    "        subj.append(b.subjectivity)\n",
    "    \n",
    "    df['title_polar']=polar\n",
    "    df['title_subj']=subj\n",
    "    return df\n",
    "\n",
    "def get_essay1_polarity_and_subjectivity(df):\n",
    "    '''Add polarity and subjectivity columns for title to df, but do not yet drop\n",
    "    essay1 column.'''\n",
    "\n",
    "    polar=[]\n",
    "    subj=[]\n",
    "    for t in df.project_essay_1:\n",
    "        b=get_textblob(t)\n",
    "        polar.append(b.polarity)\n",
    "        subj.append(b.subjectivity)\n",
    "    \n",
    "    df['essay1_polar']=polar\n",
    "    df['essay1_subj']=subj\n",
    "    return df\n",
    "\n",
    "def make_model_df(df):\n",
    "    '''Generate model df by adding dummies, droping unusable columns, and dropping\n",
    "    the approval column if necessary'''   \n",
    "\n",
    "    df1= pd.get_dummies(df, prefix='D_', columns=__columns_for_dummies__)\n",
    "    df1.drop(__non_model_columns__,inplace=True,axis=1)\n",
    "    \n",
    "    target=[]\n",
    "    \n",
    "    try:\n",
    "        # Drop target column if it exists (will be present in training data)\n",
    "        target=df1.project_is_approved.values\n",
    "        df1.drop('project_is_approved',inplace=True,axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    df=''\n",
    "    return df1,target\n",
    "\n",
    "def get_default_model_results(feats, target):\n",
    "    '''Accept features that have been processed, a target vector\n",
    "    and print the confusion matrix for Gradient Boost and Random Forrest.\n",
    "    These models can be optimized later, but use this as a means of seeing \n",
    "    impact of adding features.\n",
    "    \n",
    "    return the two created classifiers and the two confusion matrices'''\n",
    "    \n",
    "    random_state=0\n",
    "    random_state_tts=42\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.33,\\\n",
    "                                                        random_state=random_state_tts)\n",
    "\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\\\n",
    "                                 max_depth=3, random_state=random_state).fit(X_train, y_train)\n",
    "\n",
    "    ranfor=RandomForestClassifier(n_estimators=10,max_features=\"auto\",max_depth=None,\\\n",
    "                                  random_state=0).fit(X_train, y_train)\n",
    "       \n",
    "    test_cases=len(y_test)\n",
    "    print 'Total test cases:',test_cases\n",
    "\n",
    "    clf_y=clf.predict(X_test)\n",
    "    con_b=confusion_matrix(y_test,clf_y)\n",
    "    print 'clf',clf.score(X_test, y_test)\n",
    "    print_con_matrix('Gradient Boost',con_b)\n",
    "    rocky_gb=roc_auc_score(y_test, clf.predict_proba(X_test)[:,1])\n",
    "    print 'GB roc_aucscore_= {:6.5f}'.format(rocky_gb)\n",
    "\n",
    "    ranfor_y=ranfor.predict(X_test)\n",
    "    con_f=confusion_matrix(y_test,ranfor_y)\n",
    "    print 'ranfor',ranfor.score(X_test, y_test)\n",
    "    print_con_matrix('Random Forest',con_f)\n",
    "    \n",
    "    rocky_rf=roc_auc_score(y_test, ranfor.predict_proba(X_test)[:,1])\n",
    "    print 'RF roc_aucscore_= {:6.5f}'.format(rocky_rf)\n",
    "    \n",
    "    return clf,con_b,rocky_gb,ranfor,con_f,rocky_rf\n",
    "\n",
    "def get_known_state_file():\n",
    "    '''Generate working file of known state.  Actions are:\n",
    "    open file, add month, 1st subject, change id to proj_id\n",
    "    project_costs, and current projects/teacher'''\n",
    "    df=get_raw_training_file()\n",
    "    df=add_month_column(df)\n",
    "    df=get_1st_proj_sub_cat(df)\n",
    "    df.rename(columns={'id': 'proj_id'}, inplace=True)\n",
    "    df=get_proj_costs_for_df(df)\n",
    "    df=get_currents_per_teacher(df)\n",
    "    df['exp_bin']=df.apply(\\\n",
    "(lambda x: int(x.teacher_number_of_previously_posted_projects/5)*5),axis=1)\n",
    "    return df\n",
    "\n",
    "def get_known_state_file2(which_df='train'):\n",
    "    '''Generate working file of known state after\n",
    "    accepting 'train' or 'test', Actions are:\n",
    "    open file, add month, 1st subject, change id to proj_id\n",
    "    project_costs, and current projects/teacher.\n",
    "    \n",
    "    Note: in this routine, the proj_id is maintained and must be stripped later.'''\n",
    "    \n",
    "    if which_df=='train':\n",
    "        df=get_proj_costs2(which_df)\n",
    "    elif which_df=='test':\n",
    "        df=get_proj_costs2(which_df)\n",
    "    else:\n",
    "        print \"which_df must be 'train' or 'test'\"\n",
    "        return 'Wrong description.'\n",
    "    df=add_month_column(df)\n",
    "    df=get_1st_proj_sub_cat(df)\n",
    "    df.rename(columns={'id': 'proj_id'}, inplace=True)\n",
    "    df=get_currents_per_teacher(df)\n",
    "    df['exp_bin']=df.apply(\\\n",
    "(lambda x: int(x.teacher_number_of_previously_posted_projects/5)*5),axis=1)\n",
    "    return df\n",
    "\n",
    "def make_model_df2(df):\n",
    "    '''\n",
    "    Call:  returned_df,target,proj_ids=make_model_df2(known_state_df)\n",
    "    \n",
    "    Generate model df by adding dummies, droping unusable columns, and dropping\n",
    "    the approval column if necessary.  It returns a target if it exists, the list of proj ids being worked on,\n",
    "    and a working df\n",
    "    \n",
    "    NOTE:  Do not run train_test_split after calling this method'''   \n",
    "    \n",
    "    proj_ids=[]\n",
    "    target=[]\n",
    "    \n",
    "    try:\n",
    "        proj_ids=df.proj_id.values\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    df1=df\n",
    "    \n",
    "    try:\n",
    "        df1= pd.get_dummies(df, prefix='D_', columns=__columns_for_dummies__)\n",
    "        print 'dummies done'\n",
    "    except:\n",
    "        print __columns_for_dummies__\n",
    "        print 'columns',df1.columns\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        df1.drop(__non_model_columns__,inplace=True,axis=1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # Drop target column if it exists (will be present in training data)\n",
    "        target=df1.project_is_approved.values\n",
    "        df1.drop('project_is_approved',inplace=True,axis=1)\n",
    "    except:\n",
    "        pass\n",
    "    df='' #release memory\n",
    "    return df1,target,proj_ids\n",
    "\n",
    "def analyze_var_impact(baseline,new_con_mat):\n",
    "    '''Accept the baseline confusion matrix and the new confusion matrix.\n",
    "    Subtract the baseline from the new matrix.  Improvements are represented by\n",
    "    positive numbers in the false positions (0,1) and (1,0) and negative numbers\n",
    "    on the diagonal.'''\n",
    "    \n",
    "    improvement=new_con_mat-baseline\n",
    "    total=baseline.sum()\n",
    "    base_rej=baseline[0,0]\n",
    "    new_rej=new_con_mat[0,0]\n",
    "    imp_rej=improvement[0,0]\n",
    "    rej_imp= float(imp_rej)/total*100\n",
    "\n",
    "    \n",
    "    base_fn=baseline[1,0]\n",
    "    new_fn=new_con_mat[1,0]\n",
    "    imp_fn=improvement[1,0]\n",
    "    fn_imp= -1*float(imp_fn)/total*100\n",
    "    \n",
    "    base_fp=baseline[0,1]\n",
    "    new_fp=new_con_mat[0,1]\n",
    "    imp_fp=improvement[0,1]\n",
    "    fp_imp= -1*float(imp_fp)/total*100\n",
    "    \n",
    "    base_app=baseline[1,1]\n",
    "    new_app=new_con_mat[1,1]\n",
    "    imp_app=improvement[1,1]\n",
    "    app_imp= float(imp_app)/total*100\n",
    "    \n",
    "    print ' '\n",
    "    print '\\t\\t\\tNew Model\\tBaseline\\tDelta\\t\\t Percentage'\n",
    "    print 'True Rej\\t\\t%d\\t\\t%d\\t\\t%d\\t\\t%5.2f'%(new_rej,base_rej,imp_rej,rej_imp)\n",
    "    print 'False Negatives\\t\\t%d\\t\\t%d\\t\\t%d\\t\\t%5.2f'%(new_fn,base_fn,imp_fn,fn_imp)\n",
    "    print 'False Positive\\t\\t%d\\t\\t%d\\t\\t%d\\t\\t%5.2f'%(new_fp,base_fp,imp_fp,fp_imp)\n",
    "    print 'True App\\t\\t%d\\t\\t%d\\t\\t%d\\t\\t%5.2f'%(new_app,base_app,imp_app,app_imp)\n",
    "    print ' '\n",
    "    print 'New Correct Rate(score): %5.2f'%(float(new_rej+new_app)/total)\n",
    "    print 'New False Positive Rate: %5.2f'%(float(new_fp)/total)\n",
    "    print 'New False Negative Rate: %5.2f'%(float(new_fn)/total)\n",
    "    print ''\n",
    "    return\n",
    "\n",
    "def find_approved_rejected_words(df,column):\n",
    "    '''\n",
    "    call uni_app_words,all_app_words,uni_rej_words,all_rej_words=\n",
    "                find_approved_rejected_words(df,column)\n",
    "                \n",
    "    Accept the df being worked on, and the column of interest.\n",
    "    Convert the column to TextBlob items, check which ones are part of accepted \n",
    "    and rejected proposals.\n",
    "    \n",
    "    Return four lists: unique words that are in accepted but not rejected proposals,\n",
    "    and the inverse list: unique words that are in rejected proposals  and the complete lists that \n",
    "    for each\n",
    "    \n",
    "    Note:  There could be overlap in the two lists, there is no exclusivity test run\n",
    "    at this point'''\n",
    "\n",
    "    # Find words in approved and rejected titles\n",
    "    \n",
    "    i=0\n",
    "    local_count=0\n",
    "    total_count=0\n",
    "    num_lines=0\n",
    "\n",
    "    app_word_list=[]\n",
    "    rej_word_list=[]\n",
    "    all_app_words=[]\n",
    "    all_rej_words=[]\n",
    "    \n",
    "   \n",
    "\n",
    "    for t in range(len(df.index)):\n",
    "        \n",
    "        # Trap for lists\n",
    "        cell=df.loc[t,column]\n",
    "        if isinstance(df.loc[t,column],list):\n",
    "            cell=' '.join(df.loc[t,column])\n",
    "        \n",
    "        b=get_textblob(cell)\n",
    "        b=b.lower()\n",
    "\n",
    "\n",
    "        if df.loc[t,'project_is_approved']==1:\n",
    "\n",
    "            for w in b.words:\n",
    "                app_word_list.append(w)\n",
    "        else:\n",
    "\n",
    "            for w in b.words:\n",
    "                rej_word_list.append(w)\n",
    "\n",
    "        #Make the list concatenations run faster\n",
    "        if local_count==249:\n",
    "            \n",
    "            all_rej_words=all_rej_words+rej_word_list\n",
    "            rej_word_list=[]\n",
    "            all_app_words=all_app_words+app_word_list\n",
    "            app_word_list=[]\n",
    "            local_count=0\n",
    "            \n",
    "\n",
    "        local_count+=1\n",
    "        total_count+=1\n",
    "\n",
    "    uni_app_words=list(set(all_app_words))\n",
    "    uni_rej_words=list(set(all_rej_words))\n",
    "    \n",
    "    print 'Total approved words: %d unique approved words: %d'%(len(all_app_words),len(uni_app_words))\n",
    "    print 'Total rejected words: %d unique rejected words: %d'%(len(all_rej_words),len(uni_rej_words))\n",
    "    \n",
    "    return uni_app_words,all_app_words,uni_rej_words,all_rej_words\n",
    "\n",
    "def get_high_freq_words(all_words_list):\n",
    "    '''Use text blob to get high frequency words.\n",
    "    Print top 20'''\n",
    "    \n",
    "    processed_words5=[]\n",
    "    s1=all_words_list\n",
    "    \n",
    "    \n",
    "    # Case1 all_words_list really is a list\n",
    "    \n",
    "    if type(s1) is list:\n",
    "        s2=s1\n",
    "        for w in s2:\n",
    "                t=w[1:]\n",
    "                t=t.strip('[]')\n",
    "                processed_words5.append(t)\n",
    "      \n",
    "    # Case 2 all_words_list arrives as a string of joined word  \n",
    "        \n",
    "    else:\n",
    "        #print '1',s1\n",
    "        s1=s1.replace(\"u'\",\"\")\n",
    "        s1=s1.replace(\"[\",\"\")\n",
    "        s1=s1.replace(\"]\",\"\")\n",
    "        s1=s1.replace(\"'\",\"\")\n",
    "        s2=s1.split(',')\n",
    "\n",
    "\n",
    "        for w in s2:\n",
    "            if type(s2) is list:\n",
    "                w=w.strip(' ')\n",
    "                processed_words5.append(w)\n",
    "\n",
    "    processed_words2=[x.replace(\"\\\\\",'') for x in processed_words5]\n",
    "    processed_words1=[x.replace(\"+\",'') for x in processed_words2]\n",
    "    processed_words=[t for t in processed_words1 if t not in stopwords.words('english')] \n",
    "    all_words_str=' '.join(processed_words)\n",
    "    tb1=TextBlob(all_words_str)\n",
    "    tb2=tb1.word_counts.items()\n",
    "    tb2.sort(key=lambda x:x[1])\n",
    "    return list(set(processed_words)),tb2\n",
    "\n",
    "def screen_ascii(item):\n",
    "    '''\n",
    "    Call screen_ascii(item) where item is a string or unicode object\n",
    "    return ascii string'''\n",
    "    \n",
    "    try:\n",
    "        i=item.encode(\"ascii\",\"replace\")\n",
    "    except:\n",
    "        tmp=[]\n",
    "        for c in item:\n",
    "            try:\n",
    "                tmp.append(c.encode(\"ascii\",\"ignore\"))\n",
    "            except:\n",
    "                pass\n",
    "        i=''.join(tmp)\n",
    "        \n",
    "    return i.lower()\n",
    "\n",
    "def get_high_freq_words2(all_words_list):\n",
    "    '''\n",
    "    call list_of_processed_words,freq_list = get_high_freq_words2(all_words_list)\n",
    "    \n",
    "    Use text blob to get high frequency words. Print top 20 dict entries'''\n",
    "    \n",
    "    processed_words5=[]\n",
    "    s1=all_words_list\n",
    "    \n",
    "    # Case1 all_words_list really is a list\n",
    "    \n",
    "    if type(s1) is list:\n",
    "        s1=' '.join(s1)\n",
    "      \n",
    "    # Case 2 all_words_list arrives as a string of joined word  \n",
    "    screen_ascii(s1)\n",
    "    s2=s1.split(' ')\n",
    "\n",
    "    processed_words=[t for t in s2 if t not in stopwords.words('english')]\n",
    "    \n",
    "    all_words_str=' '.join(processed_words)\n",
    "    tb1=TextBlob(all_words_str)\n",
    "    tb2=tb1.word_counts.items()\n",
    "    tb2.sort(key=lambda x:x[1])\n",
    "    \n",
    "    return list(set(processed_words)),tb2\n",
    "\n",
    "def get_word_score(list_of_words, accepted_dict, rejected_dict,scale_factor=6.0):\n",
    "    '''Simple weighting system: take each unique word, add its frequency for approved proposal words\n",
    "    and subtract its frequency for rejected proposal words'''\n",
    "    score=0\n",
    "    for w in list_of_words:\n",
    "        \n",
    "        acc_score=0\n",
    "        try:\n",
    "            acc_score=accepted_dict[w]/scale_factor\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        rej_score=0\n",
    "        try:\n",
    "            rej_score=rejected_dict[w]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        score=score+acc_score-rej_score\n",
    "    return score\n",
    "\n",
    "def get_unique_words(cell):\n",
    "    '''Accept cell which is either string of list, return list of unique words from textblob'''\n",
    "\n",
    "    processed_words5=[]\n",
    "    s1=cell\n",
    "    \n",
    "    # Case1 cell already a list\n",
    "    \n",
    "    if type(s1) is list:\n",
    "        s2=s1\n",
    "        for w in s2:\n",
    "            t=w[2:]\n",
    "            processed_words5.append(t.strip('[]'))\n",
    "            processed_words5=list(set(processed_words5))\n",
    "                #t=t.strip('[]')\n",
    "                #processed_words5.append(t)\n",
    "      \n",
    "    # Case 2 cell arrives as a string of joined word  \n",
    "        \n",
    "    else:\n",
    "        s1=s1.replace(\"u'\",\"\")\n",
    "        s1=s1.replace(\"[\",\"\")\n",
    "        s1=s1.replace(\"]\",\"\")\n",
    "        s1=s1.replace(\"'\",\"\")\n",
    "        s2=s1.split(',')\n",
    "\n",
    "\n",
    "        for w in s2:\n",
    "            if type(s2) is list:\n",
    "                #w=w.strip(' ')\n",
    "                #processed_words5.append(w)\n",
    "                processed_words5.append(w.strip('[]'))\n",
    "                processed_words5=list(set(processed_words5))\n",
    "\n",
    "    processed_words2=[x.replace(\"\\\\\",'') for x in processed_words5]\n",
    "    processed_words1=[x.replace(\"+\",'') for x in processed_words2]\n",
    "    processed_wordsf=list(set(processed_words1))\n",
    "    processed_words=[t for t in processed_wordsf if t not in stopwords.words('english')] \n",
    "    return processed_words\n",
    "\n",
    "def get_unique_screened_words(cell):\n",
    "    '''\n",
    "    call get_unique_screened_words(cell) where cell is a prescreened object\n",
    "    return list of unique words from textblob'''\n",
    "\n",
    "    \n",
    "    s1=cell\n",
    "    \n",
    "    # Case1 cell already a list\n",
    "    \n",
    "    if type(s1) is str:\n",
    "        s1=screen_ascii(s1)\n",
    "        s1=s1.split(' ')\n",
    "        \n",
    "    # s2\n",
    "    s2=list(set(s1)) \n",
    "    \n",
    "    processed_words=[t for t in s2 if t not in stopwords.words('english')] \n",
    "    return processed_words\n",
    "\n",
    "def get_processed_essay_word_freqs(df,test_column,timer):\n",
    "    '''\n",
    "    \n",
    "    Accept column name, return processed words column\n",
    "    Assumes essays tokenized'''\n",
    "    strname=test_column+'_string_tokens'\n",
    "\n",
    "    #df[strname]=df.apply((lambda x: df.loc[x.name,test_column].strip('[]')),axis=1)\n",
    "    \n",
    "    uni_app_words,all_app_words,uni_rej_words,all_rej_words=find_approved_rejected_words(df,test_column)\n",
    "    \n",
    "    #Generate frequency dicts of processed approved and rejected proposals\n",
    "    print 'At dict creation'\n",
    "    timex.get_elapsed_time(timer)\n",
    "\n",
    "    processed_rej_words,all_rej_freqs=get_high_freq_words(all_rej_words)\n",
    "    print 'High Frequency Rejected Done'\n",
    "    timex.get_elapsed_time(timer)\n",
    "    processed_app_words,all_app_freqs=get_high_freq_words(all_app_words)\n",
    "    print 'High Frequency Approved Done'\n",
    "    timex.get_elapsed_time(timer)\n",
    "    \n",
    "    all_rej_freq_dict=dict(all_rej_freqs)\n",
    "    all_app_freq_dict=dict(all_app_freqs)\n",
    "    print 'Dictionaries Complete'\n",
    "    print \"Number entries rejected:\",len(all_rej_freq_dict)\n",
    "    print \"Number entries approved:\",len(all_app_freq_dict)\n",
    "    timex.get_elapsed_time(timer)\n",
    "    \n",
    "    return all_rej_freq_dict,all_app_freq_dict\n",
    "\n",
    "def get_tokenized_column_word_freqs(df,test_column):\n",
    "    '''\n",
    "    call: all_rej_freq_dict,all_app_freq_dict=get_tokenized_column_word_freqs(df,col)\n",
    "    Accept column name, return processed words column\n",
    "    Assumes essays tokenized'''\n",
    "    strname=test_column+'_string_tokens'\n",
    "\n",
    "    #df[strname]=df.apply((lambda x: df.loc[x.name,test_column].strip('[]')),axis=1)\n",
    "    \n",
    "    uni_app_words,all_app_words,uni_rej_words,all_rej_words=find_approved_rejected_words(df,test_column)\n",
    "    \n",
    "    #Generate frequency dicts of processed approved and rejected proposals\n",
    "    print 'At dict creation'\n",
    "\n",
    "    processed_rej_words,all_rej_freqs=get_high_freq_words2(all_rej_words)\n",
    "    print 'High Frequency Rejected Done'\n",
    "\n",
    "    processed_app_words,all_app_freqs=get_high_freq_words2(all_app_words)\n",
    "    print 'High Frequency Approved Done'\n",
    "    \n",
    "    all_rej_freq_dict=dict(all_rej_freqs)\n",
    "    all_app_freq_dict=dict(all_app_freqs)\n",
    "    print 'Dictionaries Complete'\n",
    "    print \"Number entries rejected:\",len(all_rej_freq_dict)\n",
    "    print \"Number entries approved:\",len(all_app_freq_dict)\n",
    "    \n",
    "    return all_rej_freq_dict,all_app_freq_dict\n",
    "\n",
    "\n",
    "def get_tokens(cell):#,indy,timer):\n",
    "    '''\n",
    "    call tokens=get_tokens(cell)\n",
    "    Accept a string, tokenize'''\n",
    "    tmp=cell.decode('utf-8','replace')\n",
    "\n",
    "    #split and drop high frequency words\n",
    "    tmp2=tmp.split(' ')\n",
    "    tmp2[:10]\n",
    "    tmp3=[t for t in tmp2 if t not in stopwords.words('english')]\n",
    "    \n",
    "    tmp3=' '.join(tmp3)\n",
    "    # Join and tokenize\n",
    "\n",
    "    tokens = [w for w in word_tokenize(tmp3.lower()) \n",
    "                  if w.isalpha()]\n",
    "\n",
    "    #if (indy%5000==0):\n",
    "        #print indy\n",
    "        #timex.get_elapsed_time(timer)\n",
    "        \n",
    "    return tokens\n",
    "\n",
    "def check_essay_similarity(essay1,essay2):\n",
    "    '''\n",
    "    call check_essay_similarity(essay1,essay2) \n",
    "    \n",
    "    Accepts two arrays of essays, and compares the number of unique words\n",
    "    '''\n",
    "    \n",
    "    if type(essay1) is str:\n",
    "        l1=essay1.split(' ')\n",
    "    elif type(essay1) is list:\n",
    "        l1=essay1\n",
    "    else:\n",
    "        return 'Disaster'\n",
    "        \n",
    "    if type(essay2) is str:\n",
    "        l2=essay2.split(' ')\n",
    "    elif type(essay2) is list:\n",
    "        l2=essay2\n",
    "    else:\n",
    "        return 'Disaster'\n",
    "    \n",
    "    s1=set(l1)\n",
    "    s2=set(l2)\n",
    "    common=s1.intersection(s2)\n",
    "    \n",
    "    return float(len(common))/min(len(s1),len(s2))\n",
    "\n",
    "def get_column_polarity_and_subjectivity(df,col_name):\n",
    "    '''\n",
    "    Call  get_column_polarity_and_subjectivity(df,col_name) where df is the column of interest before\n",
    "    model processing and column name is a string representing the column of interest.\n",
    "    \n",
    "    Add polarity and subjectivity columns for title to df, but do not yet drop\n",
    "    essay1 column.'''\n",
    "\n",
    "    polar=[]\n",
    "    subj=[]\n",
    "    \n",
    "    for t in df[col_name]:\n",
    "        b=get_textblob(t)\n",
    "        polar.append(b.polarity)\n",
    "        subj.append(b.subjectivity)\n",
    "    \n",
    "    df[col_name+'_polar']=polar\n",
    "    df[col_name+'_subj']=subj\n",
    "    return df\n",
    "\n",
    "\n",
    "class Speller():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.l_count=0\n",
    "        self.b_count=0\n",
    "        #self.sttime=timex.get_start_time()\n",
    "        self.tblob=Blobber()\n",
    "\n",
    "    \n",
    "    def spell_check_ntlk(self,item,check_words):\n",
    "        '''accept string, split, spellcheck, return #misspelled words'''\n",
    "        #l_words=item.lower()\n",
    "        #l_words=l_words.split(' ')\n",
    "        l_words=item.split(' ')\n",
    "        # Check if word is in set\n",
    "        misspells=0\n",
    "        for w in l_words:\n",
    "            if w not in check_words:\n",
    "                misspells+=1\n",
    "                \n",
    "        #if self.l_count==50000:\n",
    "        #    print 'Done',self.b_count\n",
    "        #    timex.get_elapsed_time(self.sttime)\n",
    "        #    self.l_count=-1\n",
    "\n",
    "        #self.l_count+=1\n",
    "        #self.b_count+=1\n",
    "        \n",
    "        return misspells\n",
    "    \n",
    "def get_RF_model(feats,target,test_size=0.33):\n",
    "    '''\n",
    "    call get_RF_model(feats,target,test_size) \n",
    "    \n",
    "    where feats is a df preprocessed for modeling (numeric values only), target \n",
    "    is an aligned list, '''\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(feats, target, test_size=0.33,\\\n",
    "                                                  random_state=random_state_tts)\n",
    "                        \n",
    "    #min_samples_per leaf not optimized yet\n",
    "    ranfor = RandomForestClassifier(n_estimators=100, max_features='auto',max_depth=None, min_samples_split=16,\\\n",
    "                                                             random_state=random_state).fit(X_train, y_train)\n",
    "    \n",
    "    rscore=ranfor.score(X_test, y_test)\n",
    "    ranfor_y=ranfor.predict(X_test)\n",
    "    con_r=confusion_matrix(y_test,ranfor_y)\n",
    "    rej_guess=float(con_r[0,0]+con_r[1,0])/np.sum(con_r)\n",
    "    app_guess=float(con_r[0,1]+con_r[1,1])/np.sum(con_r)\n",
    "    \n",
    "    print \"Score%6.4f\\tRej_Guesse%6.4f\\tApp_Guesse%6.4f\"%(rscore,rej_guess,app_guess)\n",
    "    \n",
    "    return ranfor\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################################################################\n",
    "#  Simple Text Functions\n",
    "####################################################################\n",
    "def check_essay_similarity(essay1,essay2):\n",
    "    '''\n",
    "    call check_essay_similarity(essay1,essay2) \n",
    "    \n",
    "    Accepts two arrays of essays, and compares the number of unique words\n",
    "    '''\n",
    "    \n",
    "    if type(essay1) is str:\n",
    "        l1=essay1.split(' ')\n",
    "    elif type(essay1) is list:\n",
    "        l1=essay1.copy()\n",
    "    else:\n",
    "        return 'Disaster 1'\n",
    "        \n",
    "    if type(essay2) is str:\n",
    "        l2=essay2.split(' ')\n",
    "    elif type(essay2) is list:\n",
    "        l2=essay2.copy()\n",
    "    else:\n",
    "        return 'Disaster 2'\n",
    "    \n",
    "    s1=set(l1)\n",
    "    s2=set(l2)\n",
    "    common=s1.intersection(s2)\n",
    "    \n",
    "    similarity=float(len(common))/min(len(s1),len(s2))\n",
    "    del s1,s2,common,l1,l2\n",
    "    \n",
    "    return similarity\n",
    "\n",
    "def fix_essay(e):\n",
    "    if isinstance(e,str):\n",
    "        return e\n",
    "    else:\n",
    "        return ' '\n",
    "\n",
    "def count_caps(str1):\n",
    "    '''Count capital letters in a string'''\n",
    "    s2=list(str1)\n",
    "    return len([x for x in s2 if str.isupper(x)])\n",
    "\n",
    "def unique_words(str1):\n",
    "    '''Count unique words in a string'''\n",
    "    return len(set(str1.split(' ')))\n",
    "\n",
    "def get_column_polarity_and_subjectivity(df,col_name):\n",
    "    '''\n",
    "    Call  get_column_polarity_and_subjectivity(df,col_name) where df is the column of interest before\n",
    "    model processing and column name is a string representing the column of interest.\n",
    "    \n",
    "    Add polarity and subjectivity columns for title to df, but do not yet drop\n",
    "    essay1 column.'''\n",
    "\n",
    "    polar=[]\n",
    "    subj=[]\n",
    "    \n",
    "    for t in df[col_name]:\n",
    "        b=get_textblob(t)\n",
    "        polar.append(b.polarity)\n",
    "        subj.append(b.subjectivity)\n",
    "    \n",
    "    df[col_name+'_polar']=polar\n",
    "    df[col_name+'_subj']=subj\n",
    "    \n",
    "    del polar,subj\n",
    "    return df\n",
    "\n",
    "def screen_ascii(item):\n",
    "    '''\n",
    "    Call screen_ascii(item) where item is a string or unicode object\n",
    "    return ascii string'''\n",
    "    \n",
    "    try:\n",
    "        i=item.encode(\"ascii\",\"replace\")\n",
    "    except:\n",
    "        tmp=[]\n",
    "        for c in item:\n",
    "            try:\n",
    "                tmp.append(c.encode(\"ascii\",\"ignore\"))\n",
    "            except:\n",
    "                pass\n",
    "        i=''.join(tmp)\n",
    "    return i.lower()\n",
    "\n",
    "def strip_string_punctuation(s):\n",
    "    str1=s.replace(\"\\\\r\\\\n\",'')\n",
    "    str1=[c if c not in string.punctuation else c.replace(c,' ') for c in str1]\n",
    "    str1=''.join(str1)\n",
    "    return str1\n",
    "\n",
    "\n",
    "def get_word_score(list_of_words, accepted_dict, rejected_dict,scale_factor=6.0):\n",
    "    '''Simple weighting system: take each unique word, add its frequency for approved proposal words\n",
    "    and subtract its frequency for rejected proposal words'''\n",
    "    score=0\n",
    "    for w in list_of_words:\n",
    "        \n",
    "        acc_score=0\n",
    "        try:\n",
    "            acc_score=accepted_dict[w]/scale_factor\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        rej_score=0\n",
    "        try:\n",
    "            rej_score=rejected_dict[w]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        score=score+acc_score-rej_score\n",
    "    return score\n",
    "\n",
    "def drop_stops_2(s):\n",
    "    str1=s.split(' ')\n",
    "\n",
    "    s1=set(str1)\n",
    "    #s2= set(stopwords.words('english'))\n",
    "    s2= set(stopwords)\n",
    "    intersection=list(set(s1).intersection(s2))\n",
    "    \n",
    "    str1=[t for t in str1 if t not in intersection]\n",
    "    return str1\n",
    "\n",
    "def process_screened_text_for_tb_class(string):\n",
    "    '''Accept string, strip punc, brackets, commas, etc.  Return.'''\n",
    "    str1=string.strip(', \\'\\']')\n",
    "    str1=str1.strip('[')\n",
    "    str1=str1.replace(\"'\",'')\n",
    "    str1=str1.replace(\",\",'')\n",
    "    l=str1.split(' ')\n",
    "    l=[x for x in l if x!= '']\n",
    "    return ' '.join(l)\n",
    "\n",
    "def spell_check_ntlk(l_words,check_words):\n",
    "        '''accept string, split, spellcheck, return #misspelled words'''\n",
    "        #changed from string to list input\n",
    "        #l_words=item.split(' ')\n",
    "\n",
    "        # Check if word is in set\n",
    "        misspells=0\n",
    "        for w in l_words:\n",
    "            if w not in check_words:\n",
    "                misspells+=1        \n",
    "        return misspells\n",
    "\n",
    "    \n",
    "#Create Compare Dictionary\n",
    "word_list=brown.words()\n",
    "word_list2=wn.words()\n",
    "word_set=set(word_list)\n",
    "\n",
    "w2=word_set.union(set(word_list2))\n",
    "del word_list,word_list2 #release memory\n",
    "print 'w2 spelling dict created'\n",
    "##############################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_dict={'AL':'Alabama',  'AK':'Alaska', 'AZ':'Arizona', 'AR':'Arkansas', \n",
    " 'CA':'California', 'CO':'Colorado', 'CT':'Connecticut', 'DE':'Delaware', \n",
    " 'DC':'District of Columbia', 'FL':'Florida','GA':'Georgia', 'HI':'Hawaii', \n",
    " 'ID':'Idaho', 'IL':'Illinois','IN':'Indiana', 'IA':'Iowa', \n",
    " 'KS':'Kansas', 'KY':'Kentucky','LA':'Louisiana','ME':'Maine', \n",
    " 'MD':'Maryland', 'MA':'Massachusetts','MI':'Michigan','MN':'Minnesota', \n",
    " 'MS':'Mississippi', 'MO':'Missouri', 'MT':'Montana','NE':'Nebraska', \n",
    " 'NV':'Nevada', 'NH':'New Hampshire','NJ':'New Jersey','NM':'New Mexico', \n",
    " 'NY':'New York', 'NC':'North Carolina','ND':'North Dakota', 'OH':'Ohio', \n",
    " 'OK':'Oklahoma', 'OR':'Oregon','PA':'Pennsylvania','PR':'Puerto Rico', \n",
    " 'RI':'Rhode Island', 'SC':'South Carolina','SD':'South Dakota','TE':'Tennessee', \n",
    " 'TX':'Texas', 'UT':'Utah','VM':'Vermont','VA':'Virginia', \n",
    " 'WA':'Washington','WV':'West Virginia','WI':'Wisconsin', 'WY':'Wyoming'}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
